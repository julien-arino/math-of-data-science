# Introduction to Principal Components Analysis (PCA)

See this [stackexchange page](https://opendata.stackexchange.com/questions/7793/age-weight-and-height-dataset) for links to height and weight datasets. Let us try something very Canadian..


```R
data = read.csv("https://figshare.com/ndownloader/files/5303173")
head(data)
dim(data)
```


<table class="dataframe">
<caption>A data.frame: 6 × 13</caption>
<thead>
	<tr><th></th><th scope=col>year</th><th scope=col>country</th><th scope=col>no</th><th scope=col>name</th><th scope=col>position</th><th scope=col>side</th><th scope=col>height</th><th scope=col>weight</th><th scope=col>birth</th><th scope=col>club</th><th scope=col>age</th><th scope=col>cohort</th><th scope=col>bmi</th></tr>
	<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><th scope=row>1</th><td>2001</td><td>RUS</td><td>10</td><td>tverdovsky oleg    </td><td>D</td><td>L</td><td>185</td><td>84</td><td>1976-05-18</td><td>anaheim mighty ducks   </td><td>24.95277</td><td>1976</td><td>24.54346</td></tr>
	<tr><th scope=row>2</th><td>2001</td><td>RUS</td><td> 2</td><td>vichnevsky vitali  </td><td>D</td><td>L</td><td>188</td><td>86</td><td>1980-03-18</td><td>anaheim mighty ducks   </td><td>21.11978</td><td>1980</td><td>24.33228</td></tr>
	<tr><th scope=row>3</th><td>2001</td><td>RUS</td><td>26</td><td>petrochinin evgeni </td><td>D</td><td>L</td><td>182</td><td>95</td><td>1976-02-07</td><td>severstal cherepovetal </td><td>25.22930</td><td>1976</td><td>28.68011</td></tr>
	<tr><th scope=row>4</th><td>2001</td><td>RUS</td><td>28</td><td>zhdan alexander    </td><td>D</td><td>R</td><td>178</td><td>85</td><td>1971-08-28</td><td>ak bars kazan          </td><td>29.67556</td><td>1971</td><td>26.82742</td></tr>
	<tr><th scope=row>5</th><td>2001</td><td>RUS</td><td>32</td><td>orekhovsky oleg    </td><td>D</td><td>R</td><td>175</td><td>88</td><td>1977-11-03</td><td>dynamo moscow          </td><td>23.49076</td><td>1977</td><td>28.73469</td></tr>
	<tr><th scope=row>6</th><td>2001</td><td>RUS</td><td> 4</td><td>zhukov sergei      </td><td>D</td><td>L</td><td>193</td><td>93</td><td>1975-11-23</td><td>lokomotiv yaroslavl    </td><td>25.43737</td><td>1975</td><td>24.96711</td></tr>
</tbody>
</table>




<style>
.list-inline {list-style: none; margin:0; padding: 0}
.list-inline>li {display: inline-block}
.list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex}
</style>
<ol class=list-inline><li>6292</li><li>13</li></ol>



In case you are wondering, this is a database of ice hockey players at IIHF world championships, 2001-2016, assembled by the dataset's author. See some comments [here](https://ikashnitsky.github.io/2017/ice-hockey-players-height/). As usual, it is a good idea to plot this to get a sense of the lay of the land.


```R
plot(data$height, data$weight,
    pch = 19, col = "dodgerblue4",
    xlab = "Height (cm)", ylab = "Weight (kg)")
```


    
![png](output_3_0.png)
    


The author of the study is interested in the evolution of weights, so it is likely that the same person will be in the dataset several times. Let us check this. First check will be `FALSE` if the number of unique names does not match the


```R
length(unique(data$name)) == dim(data)[1]
length(unique(data$name))
```


FALSE



3278


We are not interested in the evolution of weights, so far, so let us simplify things: if we have more than one record for someone, let us take their weight as the average of the weights recorded for them. To be extra careful, we could check as well that there are no major variations on player height, as this could indicate homonymies.


```R
# First, we make a data frame with just the names
data_simplified = data.frame(name = unique(data$name))
w = c()
h = c()
for (n in data_simplified$name) {
    tmp = data[which(data$name == n),]
    h = c(h, mean(tmp$height))
    w = c(w, mean(tmp$weight))
}
data_simplified$weight = w
data_simplified$height = h

head(data_simplified)
# Now keep that data (and call it data so it's easier)
data = data_simplified
```


<table class="dataframe">
<caption>A data.frame: 6 × 3</caption>
<thead>
	<tr><th></th><th scope=col>name</th><th scope=col>weight</th><th scope=col>height</th></tr>
	<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><th scope=row>1</th><td>tverdovsky oleg    </td><td>84.0</td><td>185.0</td></tr>
	<tr><th scope=row>2</th><td>vichnevsky vitali  </td><td>86.0</td><td>188.0</td></tr>
	<tr><th scope=row>3</th><td>petrochinin evgeni </td><td>95.0</td><td>182.0</td></tr>
	<tr><th scope=row>4</th><td>zhdan alexander    </td><td>85.5</td><td>178.5</td></tr>
	<tr><th scope=row>5</th><td>orekhovsky oleg    </td><td>88.0</td><td>175.0</td></tr>
	<tr><th scope=row>6</th><td>zhukov sergei      </td><td>92.5</td><td>193.0</td></tr>
</tbody>
</table>




```R
plot(data$height, data$weight,
    pch = 19, col = "dodgerblue4",
    xlab = "Height (cm)", ylab = "Weight (kg)")
```


    
![png](output_8_0.png)
    


Let us centre the data and plot the result.


```R
data$weight.c = data$weight-mean(data$weight)
data$height.c = data$height-mean(data$height)
plot(data$height.c, data$weight.c,
    pch = 19, col = "dodgerblue4",
    xlab = "Height (cm)", ylab = "Weight (kg)")
```


    
![png](output_10_0.png)
    



```R
mean(data$weight)
mean(data$height)
```


87.715546535696



183.859598468781


The function `cov` returns the covariance of two samples. Note that the functions deals equally well with data that is not centred as with data that is centred.


```R
cov(data$height, data$weight)
cov(data$height.c, data$weight.c)
```


26.6350551827872



26.6350551827872


As we could see from plotting the data, there is a positive linear relationship between the two variables. Let us compute the sample covariance matrix.


```R
# Select X as the matrix we want to process
X = as.matrix(data[,c("height.c", "weight.c")])
S = 1/(dim(X)[1]-1)*t(X) %*% X
S
```


<table class="dataframe">
<caption>A matrix: 2 × 2 of type dbl</caption>
<thead>
	<tr><th></th><th scope=col>height.c</th><th scope=col>weight.c</th></tr>
</thead>
<tbody>
	<tr><th scope=row>height.c</th><td>29.66176</td><td>26.63506</td></tr>
	<tr><th scope=row>weight.c</th><td>26.63506</td><td>47.81112</td></tr>
</tbody>
</table>



The off-diagonal entries do match the computed covariance. Let us check that the variances are indeed a match too.


```R
var(X[,1])
var(X[,2])
```


29.6617624478238



47.8111221341134


Hey, that works. Is math not cool? ;)

Okay, joke aside, let us now compute the principal components. For this, we need eigenvalues and eigenvectors.


```R
ev = eigen(S)
ev
```


    eigen() decomposition
    $values
    [1] 66.87496 10.59793
    
    $vectors
              [,1]       [,2]
    [1,] 0.5820222 -0.8131729
    [2,] 0.8131729  0.5820222



The result of a call to `eigen` will not necessarily be well ordered. (Here, we are in 2D, so chances are good. When we increase the size, things might become more iffy.) So we order the eigenvalues in decreasing order and apply the same ordering to the eigenvectors. (As the eigenvectors are the columns of `ev$vectors`, we order the columns.


```R
idx_order = order(ev$values, decreasing = TRUE)
ev$values = ev$values[idx_order]
ev$vectors = ev$vectors[, idx_order]
ev
```


    eigen() decomposition
    $values
    [1] 66.87496 10.59793
    
    $vectors
              [,1]       [,2]
    [1,] 0.5820222 -0.8131729
    [2,] 0.8131729  0.5820222



Let us normalise the first eigenvector. This way, we now that the variance of the first principal component will be the corresponding eigenvalue.


```R
ev$vectors[,1] = ev$vectors[,1] / sqrt(sum(ev$vectors[,1]^2))
ev$vectors[,1]
sum(ev$vectors[,1]^2)
```


<style>
.list-inline {list-style: none; margin:0; padding: 0}
.list-inline>li {display: inline-block}
.list-inline>li:not(:last-child)::after {content: "\00b7"; padding: 0 .5ex}
</style>
<ol class=list-inline><li>0.582022198525067</li><li>0.813172897005334</li></ol>




1


Let us plot this first eigenvector (well, the line carrying this first eigenvector). To use the function `abline`, we need to give the coefficients of the line in the form of (intercept,slope). Intercept is easy, as the line goes through the origin (by construction and because we have centred the data). The slope is also quite simple..


```R
plot(data$height.c, data$weight.c,
    pch = 19, col = "dodgerblue4",
    xlab = "Height (cm)", ylab = "Weight (kg)")
abline(a = 0, b = ev$vectors[2,1]/ev$vectors[1,1], 
       col = "red", lwd = 3)
```


    
![png](output_25_0.png)
    


Let us rotate the data so that the red line becomes the "x-axis". To do that, we use a rotation matrix,
$$
R_\theta = \begin{pmatrix}
\cos\theta & -\sin\theta \\
\sin\theta & \cos\theta
\end{pmatrix}.
$$
To find the angle $\theta$, recall that $\tan\theta$ is equal to opposite length over adjacent length, i.e., 
$$
\tan\theta = \frac{\tt ev\$vectors[2,1]}{\tt ev\$vectors[1,1]}
$$
So we just use the $\arctan$ of this. (Note that angles are in radians.)


```R
theta = atan(ev$vectors[2,1]/ev$vectors[1,1])
theta
R_theta = matrix(c(cos(theta), -sin(theta),
                  sin(theta), cos(theta)),
                nr = 2, byrow = TRUE)
R_theta
```


0.949583042574389



<table class="dataframe">
<caption>A matrix: 2 × 2 of type dbl</caption>
<tbody>
	<tr><td>0.5820222</td><td>-0.8131729</td></tr>
	<tr><td>0.8131729</td><td> 0.5820222</td></tr>
</tbody>
</table>



And now we rotate the points. (In this case, we think of the points as vectors, of course.)


```R
tmp_in = matrix(c(data$weight.c, data$height.c),
                nc = 2)
tmp_out = c()
for (i in 1:dim(tmp_in)[1]) {
    tmp_out = rbind(tmp_out,
                    t(R_theta %*% tmp_in[i,]))
}
data$weight.c_r = tmp_out[,1]
data$height.c_r = tmp_out[,2]
```


```R
plot(data$height.c_r, data$weight.c_r,
    pch = 19, col = "dodgerblue4",
    xlab = "x-axis", ylab = "y-axis")
```


    
![png](output_30_0.png)
    


Note that the axes have changed quite a lot, hence the very different aspect. Let us plot with the same range as for the non-rotated data for the y-axis.


```R
plot(data$height.c_r, data$weight.c_r,
    pch = 19, col = "dodgerblue4",
    xlab = "x-axis", ylab = "y-axis",
    ylim = range(data$weight.c))
abline(h = 0, col = "red", lwd = 2)
```


    
![png](output_32_0.png)
    


Now do things "properly".


```R
if (!require("pracma")) {
    install.packages("pracma")
    library(pracma)
}
```

    Loading required package: pracma
    



```R
GS = pracma::gramSchmidt(A = ev$vectors)
```


```R
GS
```


<dl>
	<dt>$Q</dt>
		<dd><table class="dataframe">
<caption>A matrix: 2 × 2 of type dbl</caption>
<tbody>
	<tr><td>0.5820222</td><td>-0.8131729</td></tr>
	<tr><td>0.8131729</td><td> 0.5820222</td></tr>
</tbody>
</table>
</dd>
	<dt>$R</dt>
		<dd><table class="dataframe">
<caption>A matrix: 2 × 2 of type dbl</caption>
<tbody>
	<tr><td>1</td><td>-5.551115e-17</td></tr>
	<tr><td>0</td><td> 1.000000e+00</td></tr>
</tbody>
</table>
</dd>
</dl>



Now recall we saw a theorem that told us how to construct a new basis..


```R
A=matrix(c(GS$Q,1,0,0,1), nr = 2)
A
pracma::rref(A)
P = pracma::rref(A)[,c(3,4)]
P
X.new = X %*% t(P)
#for (i in 1:dim(X)[1]) {
#    X.new[i,] = P %*% X[i,]
#}
plot(X.new[,1], X.new[,2],
    pch = 19, col = "dodgerblue4")
```


<table class="dataframe">
<caption>A matrix: 2 × 4 of type dbl</caption>
<tbody>
	<tr><td>0.5820222</td><td>-0.8131729</td><td>1</td><td>0</td></tr>
	<tr><td>0.8131729</td><td> 0.5820222</td><td>0</td><td>1</td></tr>
</tbody>
</table>




<table class="dataframe">
<caption>A matrix: 2 × 4 of type dbl</caption>
<tbody>
	<tr><td>1</td><td>0</td><td> 0.5820222</td><td>0.8131729</td></tr>
	<tr><td>0</td><td>1</td><td>-0.8131729</td><td>0.5820222</td></tr>
</tbody>
</table>




<table class="dataframe">
<caption>A matrix: 2 × 2 of type dbl</caption>
<tbody>
	<tr><td> 0.5820222</td><td>0.8131729</td></tr>
	<tr><td>-0.8131729</td><td>0.5820222</td></tr>
</tbody>
</table>




    
![png](output_38_3.png)
    

