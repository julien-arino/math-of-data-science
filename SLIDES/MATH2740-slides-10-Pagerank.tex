%\PassOptionsToPackage{landscape}{geometry}
\documentclass[aspectratio=169]{beamer}

\input{slides_setup_nonLightBoard_whiteBG.tex}

\title{Markov chains, Eigenvector centrality \& PageRank}
\date{}

\begin{document}
\DeclareFontShape{OT1}{cmss}{b}{n}{<->ssub * cmss/bx/n}{} 
\begin{frame}
	\titlepage
\end{frame}


%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{What makes an important webpage?}
	In days of yore, the web was a small thing
	\vfill
	Alta Vista was the search engine of choice
	\vfill
	Google started in 1998, based on an algorithm (PageRank) described in a paper of Page, Brin, Motwani and Winograd
\end{frame}

\begin{frame}{Overview}
	Give each page a rating (of its importance), a recursively defined measure whereby a page becomes important if important pages link to it
	\vfill
	Recursive definition: the importance of a page refers back to the importance of other pages that link to it
	\vfill
	\textbf{Random surfer} model: a random surfer on the web follows links from page to page. Page rank $\simeq$ $\mathbb{P}$ random surfer lands on a particular page. Popular page $\implies$ higher probability to go there.  
	($\IP$ stands for ``probability'')
	\vfill Example of a Markov chain
\end{frame}

%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%
\section{Markov chains}
\begin{frame}{Markov chain}
	A Markov chain is a \emph{stochastic process} in which the evolution through time depends only on the current state of the system (we say the process is \emph{memoryless})
	\vfill
	Markov chains are an interesting combination of matrix theory and graph theory
	\vfill
	They form the theoretical foundation for Hidden Markov processes or Markov Chain Monte Carlo (MCMC) methods, are used in ML
\end{frame}



\begin{frame}
Conduct an experiment with a set of $n$ possible outcomes
\[
S=\{S_1,\dots, S_n\}
\]
\vfill
Experiment repeated $t$ times (with $t$ large, potentially infinite)
\vfill 
System has \emph{no memory}: the next state depends only on the present state
\vfill
Probability of $S_i$ occurring on the next step, given that $S_j$ occurred on the last step, is
\[
p_{ij}=p(S_i|S_j)
\]
\end{frame}


\begin{frame} 
Suppose that $S_i$ is the current state, then one of $S_1, \ldots,S_n$ must be the next state; so
\[
p_{1i}+p_{2i}+\cdots+p_{ni}=1, \quad 1\leq i\leq n
\]
(Some of the $p_{ij}$ can be zero, all that is needed is that $\sum_{j=1}^n p_{ij}=1$ for all $i$)
\vfill
\begin{definition}
An experiment with finite number of possible outcomes $S_1,\ldots,S_n$ is repeated. The sequence of outcomes is a \textbf{Markov chain} if there is a set of $n^2$ numbers $\{p_{ij}\}$ such that the conditional probability of outcome $S_i$ on any experiment given outcome $S_j$ on the previous experiment is $p_{ij}$, i.e., for $1\leq i,j\leq n$, $t=1,\ldots$,
\[
	p_{ij}=\IP(S_i\textrm{ on experiment }t+1\;|\;
	S_j\textrm{ on experiment }t)	
\]
Outcomes $S_1,\ldots,S_n$ are \textbf{states} and $p_{ij}$ are \textbf{transition probabilities}. $P=[p_{ij}]$ the \textbf{transition matrix}
\end{definition}
\end{frame}


\begin{frame} 
The matrix 
\[
P=
\begin{pmatrix}
p_{11} & p_{12} & \cdots & p_{1r} \\
p_{21} & p_{22} & \cdots & p_{2r} \\
&&& \\
p_{r1} & p_{r2} & \cdots & p_{rr}
\end{pmatrix}
\]
has
\begin{itemize}
\item nonnegative entries, $p_{ij}\geq 0$
\item entries less than 1, $p_{ij}\leq 1$
\item column sum 1, which we write
\[
\sum_{i=1}^n p_{ij}=1,\quad j=1,\ldots,n
\]
or, using the notation $\nbOne^T=(1,\ldots,1)$,
\[
\nbOne^TP=\nbOne^T
\]
\end{itemize}
\end{frame}


%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%
\subsection{Running example -- Mendelian inheritance}
\begin{frame}{(super simple) Mendelian genetics}
A \emph{phenotypic trait} (eye colour, hair colour, etc.) is determined by a specific pair of alleles, each of which may be two types, say G and g
\vfill
Each individual can have
\begin{itemize}
\item GG combination (\emph{dominant})
\item Gg or gG, considered equivalent genetically (\emph{hybrid})
\item gg combination (\emph{recessive})
\end{itemize}
\vfill
Individuals bearing GG or gg alleles are \emph{homozygotes}, hybrids with Gg alleles are called \emph{heterozygotes}
\vfill
GG and gg combinations lead to different phenotypes, Gg combination leads to expressing the same phenotype as individuals bearing a GG combination, hence the name dominant given to GG
\end{frame}

\begin{frame} 
In sexual reproduction, offspring inherit one allele of the pair from each parent
\vfill
Alleles inherited from each parent are selected at random, independently of each other
\vfill
This determines probability of occurrence of each type of offspring. The offspring
\begin{itemize}
\item of two GG parents must be GG
\item of two gg parents must be gg
\item of one GG and one gg parent must be Gg
\item other cases must be examined in more detail
\end{itemize}
\end{frame}

\begin{frame}{GG and Gg parents}
Suppose one parent GG and the other Gg
\vfill
\begin{center}
	\includegraphics[width=0.9\textwidth]{FIGS_slides/dominant_hybrid}
\end{center}
\begin{center}
\begin{tabular}{c|c}
& Parent 1 \\ 
\hline
Parent 2 &
\begin{tabular}{c|cc}
& G & G \\
\hline
G & GG & GG \\
g & Gg & Gg
\end{tabular}
\end{tabular}
\end{center}
To determine $\IP$ that offspring is of a certain type, count number of outcomes of each type (GG and Gg) and divide by 4
\vfill
$\implies$ offspring have probability
\begin{itemize}
\item $1/2$ of being GG
\item $1/2$ of being Gg
\end{itemize}
\end{frame}


\begin{frame}{Gg and Gg parents}
Both parents are hybrid
\vfill
\begin{center}
\includegraphics[width=\textwidth]{FIGS_slides/hybrid_hybrid}
\end{center}
\vfill
$\implies$ offspring have probability
\begin{itemize}
\item $1/4$ of being GG
\item $1/2$ of being Gg 
\item $1/4$ of being gg
\end{itemize}
\end{frame}


\begin{frame}{gg and Gg parents}
Recessive and hybrid parents
\vfill
\begin{center}
	\includegraphics[width=\textwidth]{FIGS_slides/recessive_hybrid}
\end{center}
\vfill
$\implies$ offspring have probability 
\begin{itemize}
\item $1/2$ of being Gg 
\item $1/2$ of being gg
\end{itemize}
\end{frame}




%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%
\subsection{Repetition of the process}
\begin{frame}{General case}
$p_i(t)$: probability that state $S_i$ occurs on the $t^{th}$ repetition of the experiment, $1\leq i\leq n$
\vfill
Since one the states $S_i$ must occur on the $t^{th}$ repetition
\[
p_1(t)+p_2(t)+\cdots+p_n(t)=1
\]
$p_i(t+1)$: probability that state $S_i$, $1\leq i\leq r$, occurs on $(t+1)^{th}$ repetition of the experiment
\vfill
$n$ ways to be in state $S_i$ at step $t+1$:
\begin{enumerate}
\item Step $t$ is $S_1$. Probability of getting $S_1$ on $t^{th}$ step is $p_1(t)$, and probability of having $S_i$ after $S_1$ is $p_{i1}$. Therefore $P(S_i|S_1)=p_{i1}p_1(t)$
\item We get $S_2$ on step $t$ and $S_i$ on step $(t+1)$. Then $P(S_i|S_2)=p_{2i}p_2(t)$
\item[..]
\item[n.] Probability of occurrence of $S_i$ at step $t+1$ if $S_n$ at step $t$ is $P(S_i|S_n)=p_{in}p_n(t)$
\end{enumerate}
\end{frame}


\begin{frame}
\begin{align*}
\implies
p_i(t+1) &= P(S_i|S_1)+\cdots+P(S_i|S_n) \\
&= p_{i1}p_1(t)+\cdots+p_{in}p_n(t)
\end{align*}
Therefore,
\begin{align*}
p_1(t+1) &= p_{11}p_1(t)+p_{12}p_2(t)+\dots+p_{1n}p_n(t) \\
& \;\;\vdots\\
p_n(t+1) &= p_{n1}p_1(t)+p_{n2}p_2(t)+\dots+p_{nn}p_n(t)
\end{align*}
\vfill
In matrix form
\[
p(t+1)=Pp(t), \quad n=1,2,3,\dots
\]
where $p(t)=(p_1(t),p_{2}(t),\dots , p_n(t))^T$ is a probability vector and $P=(p_{ij})$ is an $n\times n$ \emph{transition matrix},
\[
P=
\begin{pmatrix}
p_{11} & p_{12} & \cdots & p_{1r} \\
p_{21} & p_{22} & \cdots & p_{2r} \\
&&& \\
p_{r1} & p_{r2} & \cdots & p_{rr}
\end{pmatrix}
\]
\end{frame}


\begin{frame}
So
\[
\begin{pmatrix}
	p_1(t+1)\\ \vdots\\ p_n(t+1)
\end{pmatrix}
=
\begin{pmatrix}
p_{11} & p_{12} & \cdots & p_{1r} \\
p_{21} & p_{22} & \cdots & p_{2r} \\
&&& \\
p_{r1} & p_{r2} & \cdots & p_{rr}
\end{pmatrix}
\begin{pmatrix}
	p_1(t)\\ \vdots\\ p_n(t)
\end{pmatrix}
\]
\vfill
Easy to check that this gives the same expression as before
\end{frame}



\begin{frame}{Stochastic matrices}
\begin{definition}[Stochastic matrix]
The nonnegative $n\times n$ matrix $M$ is \textbf{row-stochastic} (resp. \textbf{column-stochastic}) if $\sum_{j=1}^na_{ij}=1$ for all $i=1,\dots,n$ (resp. $\sum_{i=1}^na_{ij}=1$ for all $j=1,\dots,n$)
\end{definition}
\vfill
We often say \textbf{stochastic} and let the context determine whether we mean row- or column-stochastic
\vfill
If it is both row- and column-stochastic, the matrix is \textbf{doubly stochastic}
\vfill
\begin{theorem}\label{th:spectrum_stochastic_matrix}
Let $M$ be a stochastic matrix. Then all eigenvalues $\lambda$ of $M$ are such that $|\lambda|\leq 1$. 
Furthermore, $\lambda =1$ is an eigenvalue of $M$
\end{theorem}
\end{frame}

\begin{frame}{Long time behaviour}
Let $p(0)$ be the initial distribution vector. Then
\begin{align*}
p(1) &= Pp(0) \\
p(2) &= Pp(1)\\
&= P(Pp(0)) \\
&= P^2p(0)
\end{align*}
\vfill
Iterating, we get, for any $t$,
\[
p(t)=P^tp(0)
\]
\vfill
Therefore, 
\begin{align*}
\lim_{t\rightarrow +\infty}p(t) &=
\lim_{t\rightarrow +\infty}P^tp(0) \\
&=\left(\lim_{t\rightarrow +\infty}P^t\right)p(0)
\end{align*}
if this limit exists
\end{frame}


\begin{frame}
\[
\lim_{n\rightarrow +\infty}p(t) = 
\left(\lim_{t\rightarrow +\infty}P^t\right)p(0)
\]
Does the limit exist?
\vfill
\begin{theorem}
If $M,N$ are nonsingular stochastic matrices, then $MN$ is a stochastic matrix
\end{theorem}
\vfill
\begin{corollary}
If $M$ is a nonsingular stochastic matrix, then for any $k\in\IN$, $M^k$ is a stochastic matrix
\end{corollary}
\vfill
So $P^t$ above is stochastic
\end{frame}

\subsection{Regular Markov chains}
\begin{frame}{Regular Markov chains}
\begin{definition}[Regular Markov chain]
A \textbf{regular} Markov chain has $P^k$ (entry-wise) positive for some integer $k>0$, i.e., $P^k$ has only positive entries
\end{definition}
\vfill
\begin{definition}[Primitive matrix]
A nonnegative matrix $M$ is \textbf{primitive} if, and only if, there is an integer $k>0$ such that $M^k$ is positive.
\end{definition}
\vfill
\begin{theorem}
Markov chain regular $\iff$ transition matrix $P$ primitive
\end{theorem}
\end{frame}

\begin{frame}{Behaviour of a regular MC}
\begin{theorem}
If $P$ is the transition matrix of a regular Markov chain, then
\begin{enumerate}
\item the powers $P^t$ approach a stochastic matrix $W$
\item each column of $W$ is the same (column) vector $w=(w_1,\ldots,w_n)^T$
\item the components of $w$ are positive
\end{enumerate}
\end{theorem}
\vfill
So if the Markov chain is regular
\[
\lim_{t\rightarrow +\infty}p(t)=\lim_{t\rightarrow +\infty}P^tp(0)
=Wp(0)
\]
\end{frame}


\begin{frame}{Computing $W$}
If $p(t)$ converges, then $p(t+1)=Pp(t)$ at the limit, so $w=\lim_{t\to\infty}p(t)$ is a \textbf{fixed point} of the system. Write
\[
w=Pw
\]
and solve for $w$, i.e., find $w$ as a (right) eigenvector corresponding to the eigenvalue 1
\vfill
$w$ might have to be normalized (you want a probability vector). Check that the norm $\|w\|_1$ defined by
\[
\|w\|_1=|w_1|+\cdots+|w_n|=w_1+\cdots+w_n
\]
(since $w\geq 0$) is equal to one. If not, use
\[
\tilde w = \frac{w}{\|w\|_1}
\]
\end{frame}


\begin{frame}{Back to genetics}
Suppose we want to understand what it means to have hybrid individuals in the population
\vfill
Investigate this using a process of continued matings
\begin{itemize}
\item Start with an individual of known or unknown
genetic character (dominant, hybrid or recessive) and mate it with a hybrid
\item Assume that the mating results in at least one
offspring; choose one of the offspring at random and mate it with a hybrid
\item Repeat this process through a number of generations
\end{itemize}
\vfill
What can we expect in terms of the genetic composition of the population after a while? 
\vfill
$\implies$ consider MC with states GG, Gg and gg
\end{frame}


\begin{frame}
3 states: $S_1=\textrm{GG}$, $S_2=\textrm{Gg}$ and $S_3=\textrm{gg}$; we use GG, Gg and gg as well to name the states
\vfill
\begin{center}
\begin{tabular}{c|ccc}
$\swarrow$ & GG & Gg & gg \\
\hline
GG & 0.5 & 0.25 & 0 \\
Gg & 0.5 & 0.5 & 0.5 \\
gg & 0 & 0.25 & 0.5
\end{tabular}
\end{center}
\vfill
The transition probabilities are thus
\[
P=\begin{pmatrix}
\dfrac 12 & \dfrac 14 & 0 \\[10pt]
\dfrac 12 & \dfrac 12 & \dfrac 12 \\[10pt]
0 & \dfrac 14 & \dfrac 12
\end{pmatrix}
\]
\end{frame}

\begin{frame}
\[
P=\begin{pmatrix}
	\dfrac 12 & \dfrac 14 & 0 \\[10pt]
	\dfrac 12 & \dfrac 12 & \dfrac 12 \\[10pt]
	0 & \dfrac 14 & \dfrac 12
\end{pmatrix}
\]
so
\[
P^2=\begin{pmatrix}
\dfrac 38 & \dfrac 14 & \dfrac 18 \\[10pt]
\dfrac 12 & \dfrac 12 & \dfrac 12 \\[10pt]
\dfrac 18 & \dfrac 14 & \dfrac 38
\end{pmatrix}
\]
\vfill
$\implies$ $P$ primitive $\implies$ Markov chain regular
\vfill
\begin{theorem}
$M$ primitive if the associated connection graph is strongly connected \emph{and} there is at least one positive entry on the diagonal of $M$
\end{theorem}
\end{frame}

\begin{frame}
This is checked directly on the transition graph
\vfill
\begin{center}
\begin{tikzpicture}
	[inner sep=2mm,
	place/.style={circle,draw=blue!50,fill=blue!90,thick,minimum size=1.25cm}]
	\node [place] (GG) {GG};
	\node [place] (Gg) [right=of GG] {Gg};
	\node [place] (gg) [right=of Gg]{gg};
	\draw[->] (GG) to [bend left] node [auto] {0.5} (Gg);
	\draw[->] (GG) to [loop above] node [auto] {0.5} (GG);
	\draw[->] (Gg) to [bend left] node [auto] {0.25} (GG);
	\draw[->] (Gg) to [bend left] node [auto] {0.25} (gg);
	\draw[->] (Gg) to [loop above] node [auto] {0.5} (Gg);
	\draw[->] (gg) to [bend left] node [auto] {0.5} (Gg);
	\draw[->] (gg) to [loop above] node [auto] {0.5} (gg);
\end{tikzpicture}
\end{center}
\end{frame}

\begin{frame}
Compute (right) eigenvector associated to 1
\[
\begin{pmatrix}
	1/2 & 1/4 & 0 \\
	1/2 & 1/2 & 1/2 \\
	0 & 1/4 & 1/2
\end{pmatrix}
\begin{pmatrix}
	w_1\\w_2\\w_3
\end{pmatrix}
=
\begin{pmatrix}
	w_1\\w_2\\w_3
\end{pmatrix}
\]
\begin{align*}
\frac 12 w_1+\frac 14 w_2 &= w_1 \\
\frac 12 w_1+\frac 12 w_2+\frac 12 w_3 &= w_2 \\
\frac 14 w_2+\frac 12 w_3 &= w_3
\end{align*}
So $w_1=w_2/2$, $w_3=w_2/2$ and thus
\[
\frac 14 w_2+\frac 12 w_2 +\frac 14 w_2=w_2,
\]
that is, $w_2=w_2$, i.e., $w_2$ can take any value
\vfill
\[
\implies\quad w=\left(\dfrac 14,\dfrac 12,\dfrac 14\right)
\]
\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Absorbing Markov chains}

\begin{frame}{Changing the setting of the genetic experiment}
Suppose now the same type of experiment, but mate each new generation with a GG individual instead of a Gg individual
\vfill
\begin{center}
\begin{tikzpicture}
	[inner sep=2mm,
	place/.style={circle,draw=blue!50,fill=blue!90,thick,minimum size=1.25cm}]
	\node [place] (GG) {GG};
	\node [place] (Gg) [right=of GG] {Gg};
	\node [place] (gg) [right=of Gg]{gg};
	\draw[->] (GG) to [loop above] node [auto] {1} (GG);
	\draw[->] (Gg) to node [auto] {0.5} (GG);
	\draw[->] (Gg) to [loop above] node [auto] {0.5} (Gg);
	\draw[->] (gg) to node [auto] {1} (Gg);
\end{tikzpicture}
\end{center}
\vfill
\begin{minipage}{0.45\textwidth}
	\begin{center}
		\begin{tabular}{c|ccc}
		$\swarrow$ & GG & Gg & gg \\
		\hline
		GG & 1 & 0.5 & 0 \\
		Gg & 0 & 0.5 & 1 \\
		gg & 0 & 0 & 0
		\end{tabular}
	\end{center}
\end{minipage}
\begin{minipage}{0.45\textwidth}
	\[
		P=\begin{pmatrix}
		1 & 1/2 & 0 \\[5pt]
		0 & 1/2 & 1 \\[5pt]
		0 & 0 & 0
		\end{pmatrix}
	\]
\end{minipage}
\begin{itemize}
\item leave gg after 1 iteration and can never return
\item when we leave Gg, we can never return
\item we can never leave GG when we get there
\end{itemize}
\end{frame}


\begin{frame}{Absorbing Markov chains}
\begin{definition}[Absorbing state]
A state $S_i$ in a Markov chain is \textbf{absorbing} if whenever it occurs on the $t^{th}$ generation of the experiment, it then occurs on every subsequent step. In other words, $S_i$ is absorbing if $p_{ii}=1$ and $p_{ij}=0$ for $i\neq j$
\end{definition}
\vfill
\begin{definition}[Absorbing chain]
A Markov chain is \textbf{absorbing} if it has at least one absorbing state, and if from every state it is possible to go to an absorbing state.
In an absorbing Markov chain, a state that is not absorbing is called \textbf{transient}
\end{definition}
\end{frame}


\begin{frame}
%\begin{figure}[htbp]
%\centering
%\includegraphics[width=0.4\textwidth]{FIGS_slides/graphe_absorbant}
%\caption{Example of a graph corresponding to an absorbing Markov chain. States 1 and 4 are absorbing, states 2 and 3 are transient.}
%\label{fig:genetics_absorbing_graph}
%\end{figure}
Suppose we have a chain like the following
\begin{center}
\begin{tikzpicture}
	[inner sep=2mm,
	place/.style={circle,draw=blue!50,fill=blue!90,thick,minimum size=1cm}]
	\node [place] (1) {1};
	\node [place] (2) [right=of 1] {2};
	\node [place] (3) [right=of 2] {3};
	\node [place] (4) [right=of 3] {4};
	\draw[->] (1) to [loop above] (1);
	\draw[->] (2) to [loop above] (2);
	\draw[->] (3) to [loop above] (3);
	\draw[->] (4) to [loop above] (4);
	\draw[->] (2) to (1);
	\draw[->] (2) to [bend left] (3);
	\draw[->] (3) to [bend left] (2);
	\draw[->] (3) to (4);
\end{tikzpicture}
\end{center}
\vfill
\begin{enumerate}
\item Does the process eventually reach an absorbing state?
\item What is the average number of steps spent in a transient state, if starting in a transient state?
\item What is the average number of steps before entering an absorbing state?
\item What is the probability of being absorbed by a given absorbing state, when there are more than one, when starting in a given transient state?
\end{enumerate}
\end{frame}

\begin{frame}
The answer to the first question (``Does the process eventually reach an absorbing state?'') is given by the following result
\vfill
\begin{theorem}
In an absorbing Markov chain, the probability of reaching an absorbing state is 1
\end{theorem}
\end{frame}

\begin{frame}
To answer the other questions, write the transition matrix in \textbf{standard} form
\vfill
For an absorbing chain with $k$ absorbing states and $r-k$ transient states, write transition matrix as
\[
P=\begin{pmatrix}
\mathbb{I}_k & R \\
\b0 & Q
\end{pmatrix}
\]
with following meaning
\begin{center}\footnotesize
\begin{tabular}{ccc}
& Absorbing states & Transient states \\
Absorbing states & $\mathbb{I}_k$ & $R$ \\
Transient states & $\b0$ & $Q$
\end{tabular}
\end{center}
with $\mathbb{I}_k$ the $k\times k$ identity matrix, $\mathbf{0}$ an $(r-k)\times k$ matrix of zeros, $R$ an $k\times (r-k)$ matrix and $Q$ an $(r-k)\times(r-k)$ matrix.
The matrix $\mathbb{I}_{r-k}-Q$ is invertible. Let
\begin{itemize}
\item $N=(\mathbb{I}_{r-k}-Q)^{-1}$ the \textbf{fundamental matrix} of the MC
\item $T_i$ sum of the entries on row $i$ of $N$
\item $B=RN$
\end{itemize}
\end{frame}

\begin{frame}
Answers to our remaining questions:
\vfill
\begin{enumerate}
\setcounter{enumi}{1}
\item $N_{ij}$ average number of times the process is in the $j$th transient state if it starts in the $i$th transient state
\vfill
\item $T_i$ average number of steps before the process enters an absorbing state if it starts in the $i$th transient state
\vfill
\item $B_{ij}$ probability of eventually entering the $i$th absorbing state if the process starts in the $j$th transient state
\end{enumerate}
\vfill
\end{frame}

\begin{frame}{Back to the genetic example}
The matrix is already in standard form
\[
P=
\begin{pmatrix}
1 & \frac 12 & 0 \\
0 & \frac 12 & 1 \\
0 & 0 & 0
\end{pmatrix}
=\begin{pmatrix}
\mathbb{I}_1 & R \\
\b0 & Q
\end{pmatrix}
\]
with $\mathbb{I}_1=1$, $\mathbf{0}=(0\;\; 0)^T$ and
\[
R=\begin{pmatrix}
\frac 12 & 0
\end{pmatrix}
\qquad
Q=\begin{pmatrix}
\frac 12 & 1\\
0 & 0
\end{pmatrix}
\]
We have
\[
\mathbb{I}_2-Q=\begin{pmatrix}
1 & 0 \\
0 & 1
\end{pmatrix}
-\begin{pmatrix}
\frac 12 & 1\\
0 & 0
\end{pmatrix}
=\begin{pmatrix}
\frac 12 & -1\\
0 & 1
\end{pmatrix}
\]
so
\[
N=(\mathbb{I}_2-Q)^{-1}=
2\begin{pmatrix}
1 & 1 \\
0 & \frac 12
\end{pmatrix}=
\begin{pmatrix}
2 & 0 \\
2 & 1
\end{pmatrix}
\]
\end{frame}


\begin{frame}
We have
\[
N=
\begin{pmatrix}
	2 & 0 \\
	2 & 1
\end{pmatrix}
\]
So
\[
T=N\nbOne=\begin{pmatrix}
2\\
3
\end{pmatrix}
\]
and
\[
B=RN=
\begin{pmatrix}
	\frac 12 & 0
\end{pmatrix}
\begin{pmatrix}
	2 & 0 \\
	2 & 1
\end{pmatrix}
=
\begin{pmatrix}
1 & 1
\end{pmatrix}
\]
\end{frame}


\begin{frame}
\begin{enumerate}
\setcounter{enumi}{1}
\item $N_{ij}$ average number of times the process is in the $j$th transient state if it starts in the $i$th transient state
\[
N=
\begin{pmatrix}
2 & 0 \\
2 & 1
\end{pmatrix}
\]
\vfill
\item $T_i$ average number of steps before the process enters an absorbing state if it starts in the $i$th transient state
\[
T=\begin{pmatrix}
2\\
3
\end{pmatrix}
\]
\vfill
\item $B_{ij}$ probability of eventually entering the $i$th absorbing state if the process starts in the $j$th transient state
\[
B=
\begin{pmatrix}
	1 & 1
\end{pmatrix}
\]
\end{enumerate}
\vfill
\end{frame}


%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%
\section{Eigenvector centrality}

\begin{frame}{Constructing a stochastic matrix from an adjacency matrix}
	Let $A$ be the adjacency matrix of a simple graph $G=(V,E)$ and $D$ its degree matrix, i.e., the diagonal matrix $D=(d_{ij})$ with diagonal entries
	\[
		d_{ii} = \sum_{j=1}^n a_{ji} =\sum_{j=1}^n a_{ij}
	\]
	(Recall that $A$ symmetric since $G$ nondirected.)
	Then the matrix $AD^{-1}$ is column stochastic
	\vfill
	Indeed, let $\nbOne=(1,\ldots,1)^T$, then
	\begin{align*}
		\nbOne^TAD^{-1} = 
	\end{align*}
\end{frame}

\begin{frame}{Eigenvector centrality (undirected graph)}
Let $\bx$ be an eigenvector corresponding to the largest eigenvalue $\lambda$ of the non-negative adjacency matrix $A$ of the undirected graph $G = (V, E)$. (We often call $\lambda$ the \textbf{Perron root} of $A$ and $\bx$ a \textbf{Perron eigenvector}.)
\vfill
The \textbf{eigenvector centrality} (or \textbf{prestige score}) of vertex $i$ is the $i$th component of the eigenvector $\bx$ of the (column) stochastic matrix $N := AD^{-1}$ corresponding to the eigenvalue 1:
\[
	N\bx = \bx
\]
\vfill
Consider a particular vertex $i$ with its neighbouring vertices $\N(i)$:
\[
	x_i = \sum_{j\in\N(i)} x_j 
	= \sum_j A_{ij} x_j	
\]
\vfill
The eigenvector centrality defined this way depends both on the number of neighbours $|\N(i)|$ and the quality of its connections $x_j$, $j\in\N(i)$
\end{frame}

\begin{frame}
	Let $A = (a_{ij})$ be the adjacency matrix of a graph. The eigenvector centrality $x_{i}$ of vertex $i$ is given by
	$$
	x_i = \frac{1}{\lambda} \sum_k a_{k,i} \, x_k
	$$ 
	where $\lambda \neq 0$ is a constant. In matrix form
	$$
	\bx^T A=\lambda\bx^T
	$$

Hence the centrality vector $\bx$ is the left eigenvector of the adjacency matrix $A$ associated with the eigenvalue $\lambda$. 
\end{frame}


\begin{frame} 
The power method can be used to solve the eigenvector centrality problem. Let $m(v)$ denote the signed component of maximal magnitude of vector $v$. If there is more than one maximal component, let $m(v)$ be the first one. For instance, $m(-3,3,2) = -3$. Let $x^{(0)}$ be an arbitrary vector. For $k \geq 1$:

repeatedly compute $x^{(k)} = x^{(k-1)} A$;
normalize $x^{(k)} = x^{(k)} / m(x^{(k)})$;
until the desired precision is achieved. It follows that $x^{(k)}$ converges to the dominant eigenvector of $A$ and $m(x^{(k)})$ converges to the dominant eigenvalue of $A$. If matrix $A$ is sparse, each vector-matrix product can be performed in linear time in the size of the graph.

The method converges when the dominant (largest) and the sub-dominant (second largest) eigenvalues of $A$, respectively denoted by $\lambda_1$ and $\lambda_2$, are separated, that is they are different in absolute value, hence when $|\lambda_1| > |\lambda_2|$. The rate of convergence is the rate at which $(\lambda_2 / \lambda_1)^k$ goes to $0$. Hence, if the sub-dominant eigenvalue is small compared to the dominant one, then the method quickly converges.
\end{frame}


\begin{frame}{Why use the leading eigenvector?}
	We want a nonnegative measure, so we want a vector in $\IR_+$
	\vfill
	We know from the Perron-Frobenius Theorem that the eigenvector corresponding to the dominant eigenvalue of a nonnegative matrix is nonnegative
	\vfill
	Furthermore, if the graph is strongly connected, the matrix is irreducible and the eigenvector corresponding to the dominant eigenvalue is \emph{positive}
\end{frame}


%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%
\section{PageRank}

\begin{frame}{PageRank}
Variant of the Eigenvector centrality measure for directed network
\vfill
\textbf{Basic PageRank}
\begin{itemize}
\item Whenever a vertex $i$ has no outgoing link, we add a self-loop to $i$ such that $k^{in}_i=k^{out}_i=1$. Therefore $A_{ii}=1$ for such vertices in the adjacency matrix
\item Let $D^+$ be the diagonal matrix of outdegrees where each element $D_{ii}^+ = k_i^{out}$
\item Define a column stochastic matrix $N = A(D^+)^{-1}$
\item
The PageRank centrality of node i is equal to the 
eigenvector xi of matrix N (The leading eigenvalue is 1):
x = Nx
\end{itemize}
\end{frame}

\end{document}
