\documentclass[aspectratio=169]{beamer}

% Set lecture number for later use
<<set-lecture-number,echo=FALSE>>=
lecture_number = "09"
@

% Part common to all the lectures
\subtitle{MATH 2740 -- Mathematics of Data Science -- Lecture \Sexpr{lecture_number}}
\author{\texorpdfstring{Julien Arino\newline\url{julien.arino@umanitoba.ca}}{Julien Arino}}
\institute{Department of Mathematics @ University of Manitoba}
\date{Fall 202X}

% Title of the lecture
\title{Matrix methods -- Singular value decomposition}

<<set-options,echo=FALSE,warning=FALSE,message=FALSE>>=
# Source the code common to all lectures
source("common-code.R")
@

<<set-slide-background,echo=FALSE,results='asis'>>=
# Are we plotting for a dark background? Setting is in common-code.R, but
# cat command must run here.
cat(input_setup)
@

\begin{document}

% Cross-reference setup to reference previous lectures
%\zexternaldocument{L08-matrix-methods-QR-2-SVD-1}

% Continue theorem numbering from L08 (manual setup - check L08 for current count)
% L08 has several theorems, so we continue from where it left off
\setcounter{theorem}{6}  % Adjust this number based on actual count in L08

% Set up cross-references and counter persistence

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% TITLE AND OUTLINE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\titlepagewithfigure{FIGS-slides-admin/Gemini_Generated_Image_7iz9ft7iz9ft7iz9.jpeg}
\outlinepage{FIGS-slides-admin/Gemini_Generated_Image_iyzqdwiyzqdwiyzq.jpeg}



%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%
\Ssection{Computing the SVD}{FIGS-slides-admin/Gemini_Generated_Image_38bqnt38bqnt38bq.jpeg}

\begin{frame}{Computing the SVD (case of $\neq$ eigenvalues)}
To compute the SVD, we use the following result
\vfill
\begin{theorem}\label{th:eigenvectors_of_symmetric_are_orthogonal}
Let $A\in\M_n$ symmetric, $(\lambda_1,\bu_1)$ and $(\lambda_2,\bu_2)$ be eigenpairs, $\lambda_1\neq\lambda_2$. Then $\bu_1\bullet\bu_2=0$
\end{theorem}
\end{frame}

\begin{frame}{Proof of Theorem~\ref{th:eigenvectors_of_symmetric_are_orthogonal}}
$A\in\M_n$ symmetric, $(\lambda_1,\bu_1)$ and $(\lambda_2,\bu_2)$ eigenpairs with $\lambda_1\neq\lambda_2$
\begin{align*}
\lambda_1(\bv_1\bullet\bv_2) 
&= (\lambda_1\bv_1)\bullet\bv_2 \\
&= A\bv_1\bullet\bv_2 \\
&= (A\bv_1)^T\bv_2 \\
&= \bv_1^TA^T\bv_2 \\
&= \bv_1^T(A\bv_2)  \qquad\textrm{[$A$ symmetric so $A^T=A$]} \\
&= \bv_1^T(\lambda_2\bv_2) \\
&= \lambda_2(\bv_1^T\bv_2) \\
&= \lambda_2(\bv_1\bullet\bv_2)
\end{align*}
\vfill
So $(\lambda_1-\lambda_2)(\bv_1\bullet\bv_2)=0$. But $\lambda_1\neq\lambda_2$, so $\bv_1\bullet\bv_2=0$\hfill\qed
\end{frame}


\begin{frame}{Computing the SVD (case of $\neq$ eigenvalues)}
If all eigenvalues of $A^TA$ (or $AA^T$) are distinct, we can use Theorem~\ref{th:eigenvectors_of_symmetric_are_orthogonal}
\vfill
\begin{enumerate}
\item Compute $A^TA\in\M_n$
\item Compute eigenvalues $\lambda_1,\ldots,\lambda_n$ of $A^TA$; order them as $\lambda_1>\cdots>\lambda_n\geq 0$ ($>$ not $\geq$ since $\neq$)
\item Compute singular values $\sigma_1=\sqrt{\lambda_1},\ldots,\sigma_n=\sqrt{\lambda_n}$
\item Diagonal matrix $D$ in $\Sigma$ is either in $\M_n$ (if $\sigma_n>0$) or in $\M_{n-1}$ (if $\sigma_n=0$)
\end{enumerate}
\end{frame}


\begin{frame}
\begin{enumerate}
\setcounter{enumi}{4}
\item Since eigenvalues are distinct, Theorem~\ref{th:eigenvectors_of_symmetric_are_orthogonal} $\implies$ eigenvectors are orthogonal set. Compute these eigenvectors in the same order as the eigenvalues
\item Normalise them and use them to make the matrix $V$, i.e., $V=[\bv_1\cdots\bv_n]$
\item To find the $\bu_i$, compute, for $i=1,\ldots,r$,
\[
\bu_i = \frac{1}{\sigma_i}A\bv_i
\]
and ensure that $\|\bu_i\|=1$
\end{enumerate}
\end{frame}


\begin{frame}{Computing the SVD (case where some eigenvalues are $=$)}
\begin{enumerate}
\item Compute $A^TA\in\M_n$
\item Compute eigenvalues $\lambda_1,\ldots,\lambda_n$ of $A^TA$; order them as $\lambda_1\geq\cdots\geq\lambda_n\geq 0$
\item Compute singular values $\sigma_1=\sqrt{\lambda_1},\ldots,\sigma_n=\sqrt{\lambda_n}$, with $r\leq n$ the index of the last positive singular value
\item For eigenvalues that are distinct, proceed as before
\item For eigenvalues with multiplicity $>1$, we need to ensure that the resulting eigenvectors are LI \emph{and} orthogonal
\end{enumerate}
\end{frame}

\begin{frame}{Dealing with eigenvalues with multiplicity $>1$}
When an eigenvalue has (algebraic) multiplicity $>1$, e.g., characteristic polynomial contains a factor like $(\lambda-2)^2$, things can become a little bit more complicated
\vfill
The proper way to deal with this involves the so-called Jordan Normal Form (another matrix decomposition)
\vfill
In short: not all square matrices are diagonalisable, but all square matrices admit a JNF
\end{frame}


\begin{frame}
Sometimes, we can find several LI eigenvectors associated to the same eigenvalue. Check this. If not, need to use the following
\vfill
\begin{definition}[Generalised eigenvectors]
The vector $\bx\neq\b0$ is a \textbf{generalized eigenvector} of rank $m$ of $A\in\M_n$ corresponding to eigenvalue $\lambda$ if
\[
(A-\lambda\II)^{m}\bx = \b0
\]
but
\[
(A-\lambda\II)^{m-1}\bx\neq \b0
\]
\end{definition}
\end{frame}


\begin{frame}{Procedure for generalised eigenvectors}
$A\in\M_n$ and assume $\lambda$ eigenvalue with algebraic multiplicity $k$
\vfill
Find $\bv_1$, ``classic" eigenvector, i.e., $\bv_1\neq\b0$ s.t. $(A-\lambda\II)\bv_1=\b0$
\vfill
Find generalised eigenvector $\bv_2$ of rank 2 by solving for $\bv_2\neq\b0$,
\[
(A-\lambda\II)\bv_2 = \bv_1
\]
$\ldots$
\vfill
Find generalised eigenvector $\bv_k$ of rank $k$ by solving for $\bv_k\neq\b0$,
\[
(A-\lambda\II)\bv_k = \bv_{k-1}
\]
\vfill
Then $\{\bv_1,\ldots,\bv_k\}$ LI
\end{frame}


\begin{frame}{Back to the normal procedure}
With the LI eigenvectors $\{\bv_1,\ldots,\bv_k\}$ corresponding to $\lambda$
\vfill
Apply Gram-Schmidt to get orthogonal set
\vfill
For all eigenvalues with multiplicity $>1$, check that you either have LI eigenvectors or do what we just did
\vfill
When you are done, be back on your merry way to step 6 in the case where eigenvalues are all $\neq$
\vfill
I am caricaturing a little here: there can be cases that do not work exactly like this, but this is general enough..
\end{frame}


%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%
\Ssection{Applications of the SVD -- Least squares}{FIGS-slides-admin/Gemini_Generated_Image_38bqnt38bqnt38bq.jpeg}


\begin{frame}{Least squares revisited}
\begin{theorem}
Let $A\in\M_{mn}$, $\bx\in\IR^n$ and $\bb\in\IR^m$. The least squares problem $A\bx=\bb$ has a unique least squares solution $\tilde\bx$ of \emph{minimal length} (closest to the origin) given by
\[
\tilde\bx = A^+\bb
\]
where $A^+$ is the \emph{pseudoinverse} of $A$
\end{theorem}
\end{frame}

\begin{frame}
\begin{definition}[Pseudoinverse]
$A=U\Sigma V^T$ an SVD for $A\in\M_{mn}$, where 
\[
\Sigma = \begin{pmatrix}
D & 0 \\ 0 & 0
\end{pmatrix},
\textrm{ with }
D=\mathsf{diag}(\sigma_1,\ldots,\sigma_r)
\]
($D$ contains the nonzero singular values of $A$ ordered as usual)
\vskip0.5cm
The \textbf{pseudoinverse} (or \textbf{Moore-Penrose inverse}) of $A$ is $A^+\in\M_{nm}$ given by
\[
A^+ = V\Sigma^+ U^T
\]
with
\[
\Sigma^+ =
\begin{pmatrix}
D^{-1} & 0 \\ 0 & 0
\end{pmatrix}\in\M_{nm}
\]
\end{definition}
\end{frame}





% Save counters for next file

% Save theorem count for next file
\end{document}
