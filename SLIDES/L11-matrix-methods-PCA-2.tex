\documentclass[aspectratio=169]{beamer}\usepackage[]{graphicx}\usepackage[]{xcolor}
% maxwidth is the original width if it is less than linewidth
% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlsng}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hldef}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}

% Set lecture number for later use


% Part common to all the lectures
\subtitle{MATH 2740 -- Mathematics of Data Science -- Lecture 12}
\author{\texorpdfstring{Julien Arino\newline\url{julien.arino@umanitoba.ca}}{Julien Arino}}
\institute{Department of Mathematics @ University of Manitoba}
\date{Fall 202X}

% Title of the lecture
\title{Matrix methods -- QR factorisation}



\input{slides-setup-whiteBG.tex}

\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}

% Set up cross-references and counter persistence

% Set up cross-references and counter persistence

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% TITLE AND OUTLINE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\titlepagewithfigure{FIGS-slides-admin/Gemini_Generated_Image_7iz9ft7iz9ft7iz9.jpeg}
\outlinepage{FIGS-slides-admin/Gemini_Generated_Image_iyzqdwiyzqdwiyzq.jpeg}




%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%
\section{Principal component analysis (PCA)}
\newSectionSlide{FIGS-slides-admin/Gemini_Generated_Image_c06eixc06eixc06e.jpeg}


\begin{frame}{Dimensionality reduction}
One of the reasons the SVD is used is for dimensionality reduction. However, SVD has many many other uses
\vfill
Now we look at another dimensionality reduction technique, PCA
\vfill
PCA is often used as a blackbox technique, here we take a look at the math behind it
\end{frame}


\begin{frame}{What is PCA?}
Linear algebraic technique 
\vfill
Helps reduce a complex dataset to a lower dimensional one
\vfill
Non-parametric method: does not assume anything about data distribution (distribution from the statistical point of view)
\end{frame}

%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%
\subsection{A crash course on probability}
\newSubSectionSlide{FIGS-slides-admin/Gemini_Generated_Image_c06eixc06eixc06e.jpeg}


\begin{frame}{Brief ``review'' of some probability concepts}
Proper definition of \emph{probability} requires to use \emph{measure theory}.. will not get into details here
\vfill
A \textbf{random variable} $X$ is a \emph{measurable} function $X:\Omega\to E$, where $\Omega$ is a set of outcomes (\emph{sample space}) and $E$ is a measurable space
\vfill
$\IP(X\in S\subseteq E) = \IP(\omega\in\Omega|X(\omega)\in S)$
\vfill
\textbf{Distribution function} of a r.v., $F(x)=\IP(X\leq x)$, describes the distribution of a r.v.
\vfill
R.v. can be discrete or continuous or .. other things. 
\end{frame}

\begin{frame}
\begin{definition}[Variance]
Let $X$ be a random variable. The \textbf{variance} of $X$ is given by
\[
\Var X = E\left[\left(X-E(X)\right)^2\right]
\]
where $E$ is the expected value
\end{definition}
\vfill
\begin{definition}[Covariance]
Let $X,Y$ be jointly distributed random variables. The \textbf{covariance} of $X$ and $Y$ is given by
\[
\cov (X,Y) = E\left[\left(X-E(X)\right)\left(Y-E(Y)\right)\right]
\]
\end{definition}
\vfill
Note that $\cov(X,X)=E\left[\left(X-E(X)\right)^2\right] = \Var X$
\end{frame}

\begin{frame}{In practice: ``true law'' versus ``observation''}
In statistics: we reason on the \emph{true law} of distributions, but we usually have only access to a sample
\vfill
We then use \textbf{estimators} to .. estimate the value of a parameter, e.g., the mean, variance and covariance
\vfill
\end{frame}
    
\begin{frame}
\begin{definition}[Unbiased estimators of the mean and variance]
Let $x_1,\ldots,x_n$ be data points (the \emph{sample}) and 
\[
\bar x = \frac 1n \sum_{i=1}^n x_i
\]
be the \textbf{mean} of the data. An unbiased estimator of the variance of the sample is
\[
\sigma^2 = \frac{1}{n-1}\sum_{i=1}^n (x_i-\bar x)^2
\]
\end{definition}
\end{frame}

\begin{frame}
\begin{definition}[Unbiased estimator of the covariance]
Let $(x_1,y_1),\ldots,(x_n,y_n)$ be data points,
\[
\bar x = \frac 1n \sum_{i=1}^n x_i
\textrm{ and }
\bar y = \frac 1n \sum_{i=1}^n y_i
\]
be the means of the data. An estimator of the covariance of the sample is
\[
\cov(x,y) = \frac{1}{n}\sum_{i=1}^n (x_i-\bar x)(y_i-\bar y)
\]
\end{definition}
\end{frame}

\begin{frame}{What does covariance do?}
Variance explains how data disperses around the mean, in a 1-D case
\vfill
Covariance measures the relationship between two dimensions. E.g., height and weight
\vfill
More than the exact value, the sign is important:
\begin{itemize}
    \item $\cov(X,Y)>0$: both dimensions change in the same ``direction''; e.g., larger height usually means higher weight
    \item $\cov(X,Y)<0$: both dimensions change in reverse directions; e.g., time spent on social media and performance in this class
    \item $\cov(X,Y)=0$: the dimensions are independent from one another; e.g., sex/gender and ``intelligence''
\end{itemize}
\end{frame}

\begin{frame}{The covariance matrix}
Typically, we consider more than 2 variables.. 
\begin{definition}
Suppose $p$ random variables $X_1,\ldots,X_p$. Then the covariance matrix is the symmetric matrix
\[
\begin{pmatrix}
\cov(X_1,X_1) & \cov(X_1,X_2) & \cdots & \cov(X_1,X_p) \\
\cov(X_2,X_1) & \cov(X_2,X_2) & \cdots & \cov(X_2,X_p) \\
\vdots & \vdots & & \vdots \\
\cov(X_p,X_1) & \cov(X_p,X_2) & \cdots & \cov(X_p,X_p) 
\end{pmatrix}
\]
i.e., using the properties of covariance,
\[
\begin{pmatrix}
\Var X_1 & \cov(X_1,X_2) & \cdots & \cov(X_1,X_p) \\
\cov(X_1,X_2) & \Var X_2 & \cdots & \cov(X_2,X_p) \\
\vdots & \vdots & & \vdots \\
\cov(X_1,X_p) & \cov(X_2,X_p) & \cdots & \Var X_p 
\end{pmatrix}
\]
\end{definition}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%
\subsection{A running example: fingerprints}
\newSubSectionSlide{FIGS-slides-admin/Gemini_Generated_Image_7cansa7cansa7can.jpeg}
\begin{frame}{Example of a PCA problem}
We collect a bunch of information about a bunch of people.. for instance this data from Loughborough University
\vfill
\begin{quote}
This dataset contains the height, weight and 4 fingerprint measurements (length, width, area and circumference), collected from 200 participants.
\end{quote}
\vfill
What best describes a participant?
\end{frame}

\begin{frame}{The variables}
Each participant is associated to 11 variables
\vfill
\begin{itemize}
\item "Participant Number"
\item "Gender"
\item "Age"
\item "Dominant Hand"
\item "Height (cm) (average of 3 measurements)"
\item "Weight (kg) (average of 3 measurements)"
\item "Fingertip Temperature (°C)"
\item "Fingerprint Height (mm)"
\item "Fingerprint Width (mm)"
\item "Fingerprint Area (mm2)"
\item "Fingerprint Circumference (mm)"
\end{itemize}
\end{frame}

\begin{frame}{Nature of variables}
Variables have different natures
\vfill
\begin{itemize}
\item "Participant Number": $\in\IN$ (not interesting)
\item "Gender": categorical
\item "Age": $\in\IN$ 
\item "Dominant Hand": categorical
\item "Height (cm) (average of 3 measurements)": $\in\IR$
\item "Weight (kg) (average of 3 measurements)": $\in\IR$
\item "Fingertip Temperature (°C)": $\in\IR$
\item "Fingerprint Height (mm)": $\in\IR$
\item "Fingerprint Width (mm)": $\in\IR$
\item "Fingerprint Area (mm2)": $\in\IR$
\item "Fingerprint Circumference (mm)": $\in\IR$
\end{itemize}
\end{frame}

\begin{frame}{Setting things up}
Each participant is a row in the matrix (an \emph{observation})
\vfill
Each variable is a column
\vfill
So we have an $200\times 10$ matrix (we discard the ``Participant number'' column)
\vfill
We want to find what carries the most information
\vfill
For this, we are going to project the information in a new basis in which the first ``dimension'' will carry most variance, the second dimension will carry a little less, etc.
\vfill
In order to do so, we need to learn how to change bases
\end{frame}

%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%
\subsection{Change of basis}
\newSubSectionSlide{FIGS-slides-admin/Gemini_Generated_Image_c06eixc06eixc06e.jpeg}
\begin{frame}
	In the following slide, 
	\[
	[\bx]_\B
	\]
	denotes the coordinates of $\bx$ in the basis $\B$
	\vfill
	The aim of a change of basis is to express vectors in another coordinate system (another basis)
	\vfill
	We do so by finding a matrix allowing to move from one basis to another
\end{frame}

\begin{frame}{Change of basis}
\begin{definition}[Change of basis matrix]
$\B=\{\bu_1,\ldots,\bu_n\}$ and $\C=\{\bv_1,\ldots,\bv_n\}$ bases of vector space $V$
\vfill
The \textbf{change of basis matrix} $P_{\C\leftarrow\B}\in\M_n$,
\[
P_{\C\leftarrow\B}
=\left[
[\bu_1]_\C \cdots [\bu_n]_\C
\right]
\]
has columns the coordinate vectors $[\bu_1]_\C,\ldots,[\bu_n]_\C$ of vectors in $\B$ with respect to $\C$
\end{definition}
\vfill
\begin{theorem}
$\B=\{\bu_1,\ldots,\bu_n\}$ and $\C=\{\bv_1,\ldots,\bv_n\}$ bases of vector space $V$ and $P_{\C\leftarrow\B}$ a change of basis matrix from $\B$ to $\C$
\begin{enumerate}
\item $\forall\bx\in V$, $P_{\C\leftarrow\B}[\bx]_\B = [\bx]_\C$
\item $P_{\C\leftarrow\B}$ s.t. $\forall\bx\in V$, $P_{\C\leftarrow\B}[\bx]_\B = [\bx]_\C$ is \textbf{unique}
\item $P_{\C\leftarrow\B}$ invertible and $P_{\C\leftarrow\B}^{-1}=P_{\B\leftarrow\C}$
\end{enumerate}
\end{theorem}
\end{frame}


\begin{frame}{Row-reduction method for changing bases}
\begin{theorem}
\label{th:change-basis-construction}
$\B=\{\bu_1,\ldots,\bu_n\}$ and $\C=\{\bv_1,\ldots,\bv_n\}$ bases of vector space $V$. Let $\E$ be any basis for $V$,
\[
B = [[\bu_1]_\E,\ldots,[\bu_n]_\E] 
\textrm{ and }
C = [[\bv_1]_\E,\ldots,[\bv_n]_\E] 
\]
and let $[C|B]$ be the augmented matrix constructed using $C$ and $B$. Then
\[
RREF\left([C|B]\right)
=[\II|P_{\C\leftarrow\B}]
\]
\end{theorem}
\vfill
If working in $\IR^n$, this is quite useful with $\E$ the standard basis of $\IR^n$ (it does not matter if $\B=\E$)
\end{frame}

\begin{frame}
So the question now becomes
\begin{quote}
How do we find what new basis to look at our data in?
\end{quote}
\vfill
(Changing the basis does not change the data, just the view you have of it)
\vfill
(Think of what happens when you do a headstand.. your up becomes down, your right and left switch, but the world does not change, just your view of it)
\vfill
(Changes of bases are \emph{fundamental} operations in Science)
\end{frame}



%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%
\subsection{Back to PCA}
\newSubSectionSlide{FIGS-slides-admin/Gemini_Generated_Image_c06eixc06eixc06e.jpeg}
\begin{frame}{Setting things up}
I will use notation (mostly) as in Joliffe's \emph{Principal Component Analysis} (PDF of older version available for free from UofM Libraries)
\vfill
$\bx=(x_1,\ldots,x_p)$ vector of $p$ random variables
\end{frame}


\begin{frame} 
We seek a linear function $\bm{\alpha}_1^T\bx$ with maximum variance, where $\bm{\alpha}_1=(\alpha_{11},\ldots,\alpha_{1p})$, i.e.,
\[
\bm{\alpha}_1^T\bx = \sum_{j=1}^p\alpha_{1j}x_j
\]
\vfill
Then we seek a linear function $\bm{\alpha}_2^T\bx$ with maximum variance, uncorrelated to $\bm{\alpha}_1^T\bx$
\vfill
And we continue...
\vfill
At $k$th stage, we find a linear function $\bm{\alpha}_k^T\bx$ with maximum variance, uncorrelated to $\bm{\alpha}_1^T\bx,\ldots,\bm{\alpha}_{k-1}^T\bx$
\vfill
$\bm{\alpha}_i^T\bx$ is the $i$th \textbf{principal component} (PC)
\end{frame}

\begin{frame}{Case of known covariance matrix}
Suppose we know $\Sigma$, covariance matrix of $\bx$ (i.e., typically: we know $\bx$)
\vfill
Then the $k$th PC is 
\[
z_k=\bm{\alpha}_k^T\bx
\]
where $\bm{\alpha}_k$ is an eigenvector of $\Sigma$ corresponding to the $k$th largest eigenvalue $\lambda_k$
\vfill
If, additionally, $\|\bm{\alpha}_k\|=\bm{\alpha}_k^T\bm{\alpha}=1$, then $\lambda_k=\Var z_k$
\end{frame}


\begin{frame}{Why is that?}
Let us start with
\[
\bm{\alpha}_1^T\bx
\]
\vfill
We want maximum variance, where $\bm{\alpha}_1=(\alpha_{11},\ldots,\alpha_{1p})$, i.e.,
\[
\bm{\alpha}_1^T\bx = \sum_{j=1}^p\alpha_{1j}x_j
\]
with the constraint that $\|\bm{\alpha}_1\|=1$
\vfill
We have
\[
\Var \bm{\alpha}_1^T\bx
=\bm{\alpha}_1^T\Sigma\bm{\alpha}_1
\]
\end{frame}

\begin{frame}{Objective}
We want to maximise $\Var \bm{\alpha}_1^T\bx$, i.e.,
\[
\bm{\alpha}_1^T\Sigma\bm{\alpha}_1
\]
under the constraint that $\|\bm{\alpha}_1\|=1$
\vfill
$\implies$ use \textbf{Lagrange multipliers}
\end{frame}


\begin{frame}{Maximisation using Lagrange multipliers}
\framesubtitle{(A.k.a. super-brief intro to multivariable calculus)}
We want the max of $f(x_1,\ldots,x_n)$ under the constraint $g(x_1,\ldots,x_n)=k$
\begin{enumerate}
\item Solve
\begin{align*}
\nabla f(x_1,\ldots,x_n) &= \lambda\nabla g(x_1,\ldots,x_n) \\
g(x_1,\ldots,x_n) &= k
\end{align*}
where $\nabla=(\frac{\partial}{\partial x_1},\ldots,\frac{\partial}{\partial x_n})$ is the \textbf{gradient operator}
\item Plug all solutions into $f(x_1,\ldots,x_n)$ and find maximum values (provided values exist and $\nabla g\neq \b0$ there)
\end{enumerate}
\vfill
$\lambda$ is the \textbf{Lagrange multiplier}
\end{frame}


\begin{frame}{The gradient}
\framesubtitle{(Continuing our super-brief intro to multivariable calculus)}
$f:\IR^n\to\IR$ function of several variables, $\nabla=\left(\frac{\partial}{\partial x_1},\ldots,\frac{\partial}{\partial x_n}\right)$ the gradient operator
\vfill
Then
\[
\nabla f = \left(
\frac{\partial}{\partial x_1}f,\ldots,
\frac{\partial}{\partial x_n}f
\right)
\]
\vfill
So $\nabla f$ is a \emph{vector-valued} function, $\nabla f:\IR^n\to\IR^n$; also written as
\[
\nabla f = f_{x_1}(x_1,\ldots,x_n)\be_1+\cdots f_{x_n}(x_1,\ldots,x_n)\be_n
\]
where $f_{x_i}$ is the partial derivative of $f$ with respect to $x_i$ and $\{\be_1,\ldots,\be_n\}$ is the standard basis of $\IR^n$
\end{frame}


\begin{frame}{Bear with me..}
\framesubtitle{(You may experience a brief period of discomfort)}
$\bm{\alpha}_1^T\Sigma\bm{\alpha}_1$ and $\|\bm{\alpha}_1\|^2=\bm{\alpha}_1^T\bm{\alpha_1}$ are functions of $\bm{\alpha}_1=(\alpha_{11},\ldots,\alpha_{1p})$
\vfill
In the notation of the previous slide, we want the max of 
\[
f(\alpha_{11},\ldots,\alpha_{1p}) := \bm{\alpha}_1^T\Sigma\bm{\alpha}_1
\]
under the constraint that
\[
g(\alpha_{11},\ldots,\alpha_{1p}) := \bm{\alpha}_1^T\bm{\alpha_1} = 1
\]
and with gradient operator
\[
\nabla = \left(
\frac{\partial}{\partial \alpha_{11}},
\ldots,
\frac{\partial}{\partial \alpha_{1p}}
\right)
\]
\end{frame}


\begin{frame}{Effect of $\nabla$ on $g$}
$g$ is easiest to see:
\begin{align*}
\nabla g(\alpha_{11},\ldots,\alpha_{1p}) &=
\left(
\frac{\partial}{\partial \alpha_{11}},
\ldots,
\frac{\partial}{\partial \alpha_{1p}}
\right) (\alpha_{11},\ldots,\alpha_{1p}) 
\begin{pmatrix}
\alpha_{11}\\ \vdots\\ \alpha_{1p}
\end{pmatrix} \\
&= \left(
\frac{\partial}{\partial \alpha_{11}},
\ldots,
\frac{\partial}{\partial \alpha_{1p}}
\right) 
\left(
\alpha_{11}^2+\cdots+\alpha_{1p}^2
\right) \\
&= \left(2\alpha_{11},\ldots,2\alpha_{1p}\right)\\
&= 2\bm{\alpha}_1
\end{align*}
\vfill
(And that's a general result: $\nabla\|\bx\|_2^2=2\bx$ with $\|\cdot\|_2$ the Euclidean norm)
\end{frame}

\begin{frame}{Effect of $\nabla$ on $f$}
Expand (write $\Sigma=[s_{ij}]$ and do not exploit symmetry)
\begin{align*}
\bm{\alpha}_1^T\Sigma\bm{\alpha}_1 &=
\left(\alpha_{11},\ldots,\alpha_{1p}\right)
\begin{pmatrix}
s_{11} & s_{12} & \cdots & s_{1p} \\
s_{21} & s_{22} & \cdots & s_{2p} \\
\vdots & \vdots & & \vdots \\
s_{p1} & s_{p2} & & s_{pp}
\end{pmatrix}
\begin{pmatrix}
\alpha_{11} \\ \alpha_{12} \\ \vdots \\ \alpha_{1p}
\end{pmatrix} \\
&=
\left(\alpha_{11},\ldots,\alpha_{1p}\right)
\begin{pmatrix}
s_{11}\alpha_{11}+s_{12}\alpha_{12}+\cdots+s_{1p}\alpha_{1p} \\
s_{21}\alpha_{11}+s_{22}\alpha_{12}+\cdots+s_{2p}\alpha_{1p} \\
\vdots \\
s_{p1}\alpha_{11}+s_{p2}\alpha_{12}+\cdots+s_{pp}\alpha_{1p}
\end{pmatrix} \\
&=
(s_{11}\alpha_{11}+s_{12}\alpha_{12}+\cdots+s_{1p}\alpha_{1p})\alpha_{11} \\
&\quad +
(s_{21}\alpha_{11}+s_{22}\alpha_{12}+\cdots+s_{2p}\alpha_{1p})\alpha_{12} \\
&\quad\;\;\vdots \\
&\quad +
(s_{p1}\alpha_{11}+s_{p2}\alpha_{12}+\cdots+s_{pp}\alpha_{1p})\alpha_{1p}
\end{align*}
\end{frame}

\begin{frame}
We have
\begin{align*}
\bm{\alpha}_1^T\Sigma\bm{\alpha}_1 &=
(s_{11}\alpha_{11}+s_{12}\alpha_{12}+\cdots+s_{1p}\alpha_{1p})\alpha_{11} \\
&\quad +
(s_{21}\alpha_{11}+s_{22}\alpha_{12}+\cdots+s_{2p}\alpha_{1p})\alpha_{12} \\
&\quad\;\;\vdots \\
&\quad +
(s_{p1}\alpha_{11}+s_{p2}\alpha_{12}+\cdots+s_{pp}\alpha_{1p})\alpha_{1p} 
\end{align*}
\begin{align*}
\implies\frac{\partial}{\partial \alpha_{11}}
\bm{\alpha}_1^T\Sigma\bm{\alpha}_1  
&= 
(s_{11}\alpha_{11}+s_{12}\alpha_{12}+\cdots+s_{1p}\alpha_{1p})+s_{11}\alpha_{11} \\
&\quad + s_{21}\alpha_{12} +\cdots + s_{p1}\alpha_{1p} \\
&= s_{11}\alpha_{11}+s_{12}\alpha_{12}+\cdots+s_{1p}\alpha_{1p} \\
&\quad+
s_{11}\alpha_{11}+s_{21}\alpha_{12}+\cdots+s_{p1}\alpha_{1p} \\
&= 2(s_{11}\alpha_{11}+s_{12}\alpha_{12}+\cdots+s_{1p}\alpha_{1p})
\end{align*}
(last equality stems from symmetry of $\Sigma$)
\end{frame}

\begin{frame}
In general, for $i=1,\ldots,p$,
\begin{align*}
\frac{\partial}{\partial \alpha_{1i}}
\bm{\alpha}_1^T\Sigma\bm{\alpha}_1  
&= s_{i1}\alpha_{11}+s_{i2}\alpha_{12}+\cdots+s_{ip}\alpha_{1p}\\
&\quad+s_{i1}\alpha_{11}+s_{2i}\alpha_{12}+\cdots+s_{pi}\alpha_{1p} \\
&= 2(s_{i1}\alpha_{11}+s_{i2}\alpha_{12}+\cdots+s_{ip}\alpha_{1p})
\end{align*}
(because of symmetry of $\Sigma$)
\vfill
As a consequence,
\[
\nabla \bm{\alpha}_1^T\Sigma\bm{\alpha}_1
=2\Sigma\bm{\alpha}_1
\]
\end{frame}

\begin{frame}
So solving
\[
\nabla f(x_1,\ldots,x_n) = \lambda\nabla g(x_1,\ldots,x_n) 
\]
means solving
\[
2\Sigma\bm{\alpha}_1 = \lambda 2\bm{\alpha}_1 
\]
i.e.,
\[
\Sigma\bm{\alpha}_1 = \lambda\bm{\alpha}_1 
\]
\vfill
$\implies$
$(\lambda,\bm{\alpha}_1)$ eigenpair of $\Sigma$, with $\bm{\alpha}_1$ having unit length
\end{frame}


\begin{frame}{Picking the right eigenvalue}
$(\lambda,\bm{\alpha}_1)$ eigenpair of $\Sigma$, with $\bm{\alpha}_1$ having unit length
\vfill
But which $\lambda$ to choose?
\vfill
Recall that we want $\Var \bm{\alpha}_1^T\bx=\bm{\alpha}_1^T\Sigma\bm{\alpha}_1$ maximal
\vfill
We have
\[
\Var \bm{\alpha}_1^T\bx 
= \bm{\alpha}_1^T\Sigma\bm{\alpha}_1 
= \bm{\alpha}_1^T(\Sigma\bm{\alpha}_1) 
= \bm{\alpha}_1^T(\lambda\bm{\alpha}_1) 
= \lambda(\bm{\alpha}_1^T\bm{\alpha}_1) = \lambda
\]
\vfill
$\implies$ we pick $\lambda=\lambda_1$, the largest eigenvalue (covariance matrix symmetric so eigenvalues real)
\end{frame}


\begin{frame}{What we have this far..}
The first principal component is $\bm{\alpha}_1^T\bx$ and has variance $\lambda_1$, where $\lambda_1$ the largest eigenvalue of $\Sigma$ and $\bm{\alpha}_1$ an associated eigenvector with $\|\bm{\alpha}_1\|=1$
\vfill
We want the second principal component to be \emph{uncorrelated} with $\bm{\alpha}_1^T\bx$ and to have maximum variance $\Var \bm{\alpha}_2^T\bx=\bm{\alpha}_2^T\Sigma\bm{\alpha}_2$, under the constraint that $\|\bm{\alpha}_2\|=1$
\vfill
$\bm{\alpha}_2^T\bx$ uncorrelated to $\bm{\alpha}_1^T\bx$ if $\cov(\bm{\alpha}_1^T\bx,\bm{\alpha}_2^T\bx)=0$
\end{frame}

\begin{frame}
We have
\begin{align*}
\cov(\bm{\alpha}_1^T\bx,\bm{\alpha}_2^T\bx) &= 
\bm{\alpha}_1^T\Sigma\bm{\alpha}_2 \\
&= \bm{\alpha}_2^T\Sigma^T\bm{\alpha}_1 \\
&= \bm{\alpha}_2^T\Sigma\bm{\alpha}_1 \quad\textrm{[$\Sigma$ symmetric]} \\
&= \bm{\alpha}_2^T(\lambda_1\bm{\alpha}_1) \\
&= \lambda \bm{\alpha}_2^T\bm{\alpha}_1
\end{align*}
\vfill
So $\bm{\alpha}_2^T\bx$ uncorrelated to $\bm{\alpha}_1^T\bx$ if $\bm{\alpha}_1\perp\bm{\alpha}_2$
\vfill
This is beginning to sound a lot like Gram-Schmidt, no?
\end{frame}

\begin{frame}{In short}
Take whatever covariance matrix is available to you (known $\Sigma$ or sample $S_X$) -- assume sample from now on for simplicity
\vfill
For $i=1,\ldots,p$, the $i$th principal component is
\[
z_i = \bv_i^T\bx
\]
where $\bv_i$ eigenvector of $S_X$ associated to the $i$th largest eigenvalue $\lambda_i$
\vfill
If $\bv_i$ is normalised, then $\lambda_i=\Var z_k$
\end{frame}


\begin{frame}{Covariance matrix}
$\Sigma$ the covariance matrix of the random variable, $S_X$ the sample covariance matrix
\vfill
$X\in\M_{mp}$ the data, then the (sample) covariance matrix $S_X$ takes the form
\[
S_X = \frac{1}{n-1}X^TX
\]
where the data is centred!
\vfill
Sometimes you will see $S_X=1/(n-1)XX^T$. This is for matrices with observations in columns and variables in rows. Just remember that you want the covariance matrix to have size the number of variables, not observations, this will give you the order in which to take the product
\end{frame}

%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%
\subsection{A 2D example to begin: hockey players}
\newSubSectionSlide{FIGS-slides-admin/Gemini_Generated_Image_ee8lhqee8lhqee8l.jpeg}

\begin{frame}[fragile]{A 2D example}
See a dataset \href{https://opendata.stackexchange.com/questions/7793/age-weight-and-height-dataset}{on this page} for a dataset of height and weight of some hockey players
\vfill
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{data} \hlkwb{=} \hlkwd{read.csv}\hldef{(}\hlsng{"https://figshare.com/ndownloader/files/5303173"}\hldef{)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in file(file, "{}rt"{}): cannot open the connection to 'https://figshare.com/ndownloader/files/5303173'}}\begin{alltt}
\hlkwd{head}\hldef{(data,} \hlkwc{n}\hldef{=}\hlnum{3}\hldef{)}
\end{alltt}
\begin{verbatim}
##                                                                             
## 1 function (..., list = character(), package = NULL, lib.loc = NULL,        
## 2     verbose = getOption("verbose"), envir = .GlobalEnv, overwrite = TRUE) 
## 3 {
\end{verbatim}
\begin{alltt}
\hlkwd{dim}\hldef{(data)}
\end{alltt}
\begin{verbatim}
## NULL
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}
In case you are wondering, this is a database of ice hockey players at IIHF world championships, 2001-2016, assembled by the dataset's author
\vfill
See some comments \href{https://ikashnitsky.github.io/2017/ice-hockey-players-height/}{here}
\vfill
As usual, it is a good idea to plot this to get a sense of the lay of the land
\end{frame}


\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in (function (cond) : error in evaluating the argument 'x' in selecting a method for function 'plot': object of type 'closure' is not subsettable}}\end{kframe}
\end{knitrout}

\maxFrameImage{FIGS/L12-plot-hockey-1-1.pdf}

\begin{frame}[fragile]
The author of the study is interested in the evolution of weights, so it is likely that the same person will be in the dataset several times
\vfill
Let us check this: first check will be \code{FALSE} if the number of unique names does not match the number of rows in the dataset

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{length}\hldef{(}\hlkwd{unique}\hldef{(data}\hlopt{$}\hldef{name))} \hlopt{==} \hlkwd{dim}\hldef{(data)[}\hlnum{1}\hldef{]}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in data\$name: object of type 'closure' is not subsettable}}\begin{alltt}
\hlkwd{length}\hldef{(}\hlkwd{unique}\hldef{(data}\hlopt{$}\hldef{name))}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in data\$name: object of type 'closure' is not subsettable}}\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile]
Not interested in the evolution of weights, so simplify: if more than one record for someone, take average of recorded weights and heights
\vfill
To be extra careful, could check as well that there are no major variations on player height (homonymies?)
\vfill
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{data_simplified} \hlkwb{=} \hlkwd{data.frame}\hldef{(}\hlkwc{name} \hldef{=} \hlkwd{unique}\hldef{(data}\hlopt{$}\hldef{name))}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in data\$name: object of type 'closure' is not subsettable}}\begin{alltt}
\hldef{w} \hlkwb{=} \hlkwd{c}\hldef{()}
\hldef{h} \hlkwb{=} \hlkwd{c}\hldef{()}
\hlkwa{for} \hldef{(n} \hlkwa{in} \hldef{data_simplified}\hlopt{$}\hldef{name) \{}
    \hldef{tmp} \hlkwb{=} \hldef{data[}\hlkwd{which}\hldef{(data}\hlopt{$}\hldef{name} \hlopt{==} \hldef{n),]}
    \hldef{h} \hlkwb{=} \hlkwd{c}\hldef{(h,} \hlkwd{mean}\hldef{(tmp}\hlopt{$}\hldef{height))}
    \hldef{w} \hlkwb{=} \hlkwd{c}\hldef{(w,} \hlkwd{mean}\hldef{(tmp}\hlopt{$}\hldef{weight))}
\hldef{\}}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'data\_simplified' not found}}\begin{alltt}
\hldef{data_simplified}\hlopt{$}\hldef{weight} \hlkwb{=} \hldef{w}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'data\_simplified' not found}}\begin{alltt}
\hldef{data_simplified}\hlopt{$}\hldef{height} \hlkwb{=} \hldef{h}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'data\_simplified' not found}}\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile]
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{data} \hlkwb{=} \hldef{data_simplified}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'data\_simplified' not found}}\begin{alltt}
\hlkwd{head}\hldef{(data_simplified,} \hlkwc{n} \hldef{=} \hlnum{6}\hldef{)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'head': object 'data\_simplified' not found}}\end{kframe}
\end{knitrout}
\end{frame}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in (function (cond) : error in evaluating the argument 'x' in selecting a method for function 'plot': object of type 'closure' is not subsettable}}\end{kframe}
\end{knitrout}

\maxFrameImage{FIGS/L12-plot-hockey-2-1.pdf}

\begin{frame}[fragile]\frametitle{Centre the data}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{mean}\hldef{(data}\hlopt{$}\hldef{weight)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in (function (cond) : error in evaluating the argument 'x' in selecting a method for function 'mean': object of type 'closure' is not subsettable}}\begin{alltt}
\hlkwd{mean}\hldef{(data}\hlopt{$}\hldef{height)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in (function (cond) : error in evaluating the argument 'x' in selecting a method for function 'mean': object of type 'closure' is not subsettable}}\begin{alltt}
\hldef{data}\hlopt{$}\hldef{weight.c} \hlkwb{=} \hldef{data}\hlopt{$}\hldef{weight}\hlopt{-}\hlkwd{mean}\hldef{(data}\hlopt{$}\hldef{weight)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in data\$weight: object of type 'closure' is not subsettable}}\begin{alltt}
\hldef{data}\hlopt{$}\hldef{height.c} \hlkwb{=} \hldef{data}\hlopt{$}\hldef{height}\hlopt{-}\hlkwd{mean}\hldef{(data}\hlopt{$}\hldef{height)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in data\$height: object of type 'closure' is not subsettable}}

{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in (function (cond) : error in evaluating the argument 'x' in selecting a method for function 'plot': object of type 'closure' is not subsettable}}\end{kframe}
\end{knitrout}
\end{frame}

\maxFrameImage{FIGS/L12-plot-hockey-centred-1.pdf}



\begin{frame}[fragile]\frametitle{Covariance}
The function \code{cov} returns the covariance of two samples
\vfill
Note that the functions deals equally well with data that is not centred as with data that is centred
\vfill
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{cov}\hldef{(data}\hlopt{$}\hldef{height, data}\hlopt{$}\hldef{weight)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in data\$weight: object of type 'closure' is not subsettable}}\begin{alltt}
\hlkwd{cov}\hldef{(data}\hlopt{$}\hldef{height.c, data}\hlopt{$}\hldef{weight.c)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in data\$weight.c: object of type 'closure' is not subsettable}}\end{kframe}
\end{knitrout}
\end{frame}


\begin{frame}[fragile]\frametitle{Covariance matrix}
As we could see from plotting the data, there is a positive linear relationship between the two variables
\vfill
Let us compute the sample covariance matrix
\vfill
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{X} \hlkwb{=} \hlkwd{as.matrix}\hldef{(data[,}\hlkwd{c}\hldef{(}\hlsng{"height.c"}\hldef{,} \hlsng{"weight.c"}\hldef{)])}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in (function (cond) : error in evaluating the argument 'x' in selecting a method for function 'as.matrix': object of type 'closure' is not subsettable}}\begin{alltt}
\hldef{S} \hlkwb{=} \hlnum{1}\hlopt{/}\hldef{(}\hlkwd{dim}\hldef{(X)[}\hlnum{1}\hldef{]}\hlopt{-}\hlnum{1}\hldef{)}\hlopt{*}\hlkwd{t}\hldef{(X)} \hlopt{%*%} \hldef{X}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'X' not found}}\begin{alltt}
\hldef{S}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'S' not found}}\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile]\frametitle{Covariance matrix}
The off-diagonal entries do match the computed covariance. Let us check that the variances are indeed a match too.


\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{var}\hldef{(X[,}\hlnum{1}\hldef{])}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'X' not found}}\begin{alltt}
\hlkwd{var}\hldef{(X[,}\hlnum{2}\hldef{])}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'X' not found}}\end{kframe}
\end{knitrout}


Hey, that works. Is math not cool? ;)
\end{frame}


\begin{frame}[fragile]\frametitle{Principal components}
Now compute the principal components. We need eigenvalues and eigenvectors
\vfill
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{ev} \hlkwb{=} \hlkwd{eigen}\hldef{(S)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'S' not found}}\begin{alltt}
\hldef{ev}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'ev' not found}}\end{kframe}
\end{knitrout}
\vfill
(\code{eigen} returns eigenvalues sorted in decreasing order and normalised eigenvectors)
\end{frame}



\begin{frame}[fragile]\frametitle{First principal component}
Let us plot this first eigenvector (well, the line carrying this first eigenvector) 
\vfill
To use the function \code{abline}, we need to give the coefficients of the line in the form of (intercept,slope). Intercept is easy, as the line goes through the origin (by construction and because we have centred the data). The slope is also quite simple..
\vfill
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{plot}\hldef{(data}\hlopt{$}\hldef{height.c, data}\hlopt{$}\hldef{weight.c,}
    \hlkwc{pch} \hldef{=} \hlnum{19}\hldef{,} \hlkwc{col} \hldef{=} \hlsng{"dodgerblue4"}\hldef{,}
    \hlkwc{main} \hldef{=} \hlsng{"IIHF players 2001-2016 (with first component)"}\hldef{,}
    \hlkwc{xlab} \hldef{=} \hlsng{"Height (cm)"}\hldef{,} \hlkwc{ylab} \hldef{=} \hlsng{"Weight (kg)"}\hldef{)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in (function (cond) : error in evaluating the argument 'x' in selecting a method for function 'plot': object of type 'closure' is not subsettable}}\begin{alltt}
\hlkwd{abline}\hldef{(}\hlkwc{a} \hldef{=} \hlnum{0}\hldef{,} \hlkwc{b} \hldef{= ev}\hlopt{$}\hldef{vectors[}\hlnum{2}\hldef{,}\hlnum{1}\hldef{]}\hlopt{/}\hldef{ev}\hlopt{$}\hldef{vectors[}\hlnum{1}\hldef{,}\hlnum{1}\hldef{],}
       \hlkwc{col} \hldef{=} \hlsng{"red"}\hldef{,} \hlkwc{lwd} \hldef{=} \hlnum{3}\hldef{)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'ev' not found}}\end{kframe}
\end{knitrout}
\end{frame}

\maxFrameImage{FIGS/L12-plot-hockey-centred-evector-1.pdf}

\begin{frame}[fragile]\frametitle{Rotating the data}
Let us rotate the data so that the red line becomes the $x$-axis
\vfill
To do that, we use a rotation matrix
$$
R_\theta = \begin{pmatrix}
\cos\theta & -\sin\theta \\
\sin\theta & \cos\theta
\end{pmatrix}
$$
\vfill
To find the angle $\theta$, recall that $\tan\theta$ is equal to opposite length over adjacent length, i.e.,
$$
\tan\theta = \frac{\tt ev\$vectors[2,1]}{\tt ev\$vectors[1,1]}
$$
So we just use the $\arctan$ of this 
\vfill 
Note that angles are in radians
\end{frame}


\begin{frame}[fragile]\frametitle{Rotating the data}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{theta} \hlkwb{=} \hlkwd{atan}\hldef{(ev}\hlopt{$}\hldef{vectors[}\hlnum{2}\hldef{,}\hlnum{1}\hldef{]}\hlopt{/}\hldef{ev}\hlopt{$}\hldef{vectors[}\hlnum{1}\hldef{,}\hlnum{1}\hldef{])}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'ev' not found}}\begin{alltt}
\hldef{theta}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'theta' not found}}\begin{alltt}
\hldef{R_theta} \hlkwb{=} \hlkwd{matrix}\hldef{(}\hlkwd{c}\hldef{(}\hlkwd{cos}\hldef{(theta),} \hlopt{-}\hlkwd{sin}\hldef{(theta),}
                  \hlkwd{sin}\hldef{(theta),} \hlkwd{cos}\hldef{(theta)),}
                \hlkwc{nr} \hldef{=} \hlnum{2}\hldef{,} \hlkwc{byrow} \hldef{=} \hlnum{TRUE}\hldef{)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'theta' not found}}\begin{alltt}
\hldef{R_theta}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'R\_theta' not found}}\end{kframe}
\end{knitrout}
\end{frame}


\begin{frame}[fragile]\frametitle{Rotating the data}
And now we rotate the points
\vfill
(In this case, we think of the points as vectors, of course)
\vfill
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{tmp_in} \hlkwb{=} \hlkwd{matrix}\hldef{(}\hlkwd{c}\hldef{(data}\hlopt{$}\hldef{weight.c, data}\hlopt{$}\hldef{height.c),}
                \hlkwc{nc} \hldef{=} \hlnum{2}\hldef{)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in data\$weight.c: object of type 'closure' is not subsettable}}\begin{alltt}
\hldef{tmp_out} \hlkwb{=} \hlkwd{c}\hldef{()}
\hlkwa{for} \hldef{(i} \hlkwa{in} \hlnum{1}\hlopt{:}\hlkwd{dim}\hldef{(tmp_in)[}\hlnum{1}\hldef{]) \{}
    \hldef{tmp_out} \hlkwb{=} \hlkwd{rbind}\hldef{(tmp_out,}
                    \hlkwd{t}\hldef{(R_theta} \hlopt{%*%} \hldef{tmp_in[i,]))}
\hldef{\}}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'tmp\_in' not found}}\begin{alltt}
\hldef{data}\hlopt{$}\hldef{weight.c_r} \hlkwb{=} \hldef{tmp_out[,}\hlnum{1}\hldef{]}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in data\$weight.c\_r = tmp\_out[, 1]: object of type 'closure' is not subsettable}}\begin{alltt}
\hldef{data}\hlopt{$}\hldef{height.c_r} \hlkwb{=} \hldef{tmp_out[,}\hlnum{2}\hldef{]}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in data\$height.c\_r = tmp\_out[, 2]: object of type 'closure' is not subsettable}}\end{kframe}
\end{knitrout}
\end{frame}


\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in (function (cond) : error in evaluating the argument 'x' in selecting a method for function 'plot': object of type 'closure' is not subsettable}}\end{kframe}
\end{knitrout}

\maxFrameImage{FIGS/L12-plot-hockey-centred-evector-2-1.pdf}


\begin{frame}[fragile]\frametitle{Principal components}
Note that the axes have changed quite a lot, hence the very different aspect
\vfill
Let us plot with the same range as for the non-rotated data for the y-axis
\vfill

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{plot}\hldef{(data}\hlopt{$}\hldef{height.c_r, data}\hlopt{$}\hldef{weight.c_r,}
    \hlkwc{pch} \hldef{=} \hlnum{19}\hldef{,} \hlkwc{col} \hldef{=} \hlsng{"dodgerblue4"}\hldef{,}
    \hlkwc{xlab} \hldef{=} \hlsng{"x-axis"}\hldef{,} \hlkwc{ylab} \hldef{=} \hlsng{"y-axis"}\hldef{,}
    \hlkwc{main} \hldef{=} \hlsng{"IIHF players 2001-2016 (rotated to first component)"}\hldef{,}
    \hlkwc{ylim} \hldef{=} \hlkwd{range}\hldef{(data}\hlopt{$}\hldef{weight.c))}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in (function (cond) : error in evaluating the argument 'x' in selecting a method for function 'plot': object of type 'closure' is not subsettable}}\begin{alltt}
\hlkwd{abline}\hldef{(}\hlkwc{h} \hldef{=} \hlnum{0}\hldef{,} \hlkwc{col} \hldef{=} \hlsng{"red"}\hldef{,} \hlkwc{lwd} \hldef{=} \hlnum{2}\hldef{)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in int\_abline(a = a, b = b, h = h, v = v, untf = untf, ...): plot.new has not been called yet}}\end{kframe}
\end{knitrout}
\end{frame}


\maxFrameImage{FIGS/L12-plot-hockey-centred-rotated-1.pdf}


\begin{frame}[fragile]\frametitle{First and second principal components}
Plot the first and second eigenvectors
\vfill
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{plot}\hldef{(data}\hlopt{$}\hldef{height.c, data}\hlopt{$}\hldef{weight.c,}
    \hlkwc{pch} \hldef{=} \hlnum{19}\hldef{,} \hlkwc{col} \hldef{=} \hlsng{"dodgerblue4"}\hldef{,}
    \hlkwc{main} \hldef{=} \hlsng{"IIHF players 2001-2016 (with first and second components)"}\hldef{,}
    \hlkwc{xlab} \hldef{=} \hlsng{"Height (cm)"}\hldef{,} \hlkwc{ylab} \hldef{=} \hlsng{"Weight (kg)"}\hldef{)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in (function (cond) : error in evaluating the argument 'x' in selecting a method for function 'plot': object of type 'closure' is not subsettable}}\begin{alltt}
\hlkwd{abline}\hldef{(}\hlkwc{a} \hldef{=} \hlnum{0}\hldef{,} \hlkwc{b} \hldef{= ev}\hlopt{$}\hldef{vectors[}\hlnum{2}\hldef{,}\hlnum{1}\hldef{]}\hlopt{/}\hldef{ev}\hlopt{$}\hldef{vectors[}\hlnum{1}\hldef{,}\hlnum{1}\hldef{],}
       \hlkwc{col} \hldef{=} \hlsng{"red"}\hldef{,} \hlkwc{lwd} \hldef{=} \hlnum{3}\hldef{)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'ev' not found}}\begin{alltt}
\hlkwd{abline}\hldef{(}\hlkwc{a} \hldef{=} \hlnum{0}\hldef{,} \hlkwc{b} \hldef{= ev}\hlopt{$}\hldef{vectors[}\hlnum{2}\hldef{,}\hlnum{2}\hldef{]}\hlopt{/}\hldef{ev}\hlopt{$}\hldef{vectors[}\hlnum{1}\hldef{,}\hlnum{2}\hldef{],}
       \hlkwc{col} \hldef{=} \hlsng{"darkgreen"}\hldef{,} \hlkwc{lwd} \hldef{=} \hlnum{3}\hldef{)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'ev' not found}}\end{kframe}
\end{knitrout}
\end{frame}

\maxFrameImage{FIGS/L12-plot-hockey-centred-2evectors-1.pdf}


\begin{frame}\frametitle{Proper change of basis}
Let us change the basis so that, in the new basis, the first component is the $x$-axis and the second component is the $y$-axis
\vfill
We want to use Theorem~\ref{th:change-basis-construction}
\vfill
We need the coordinates of the new basis in the canonical basis of $\IR^2$
\vfill
Since both axes go through the origin, we can just use $y=ax$, with $a$ the slope of the lines and, say, $x=1$, i.e., $(x,y)=(1,a)$
\vfill
We then normalise the resulting vectors
\end{frame}


\begin{frame}[fragile]\frametitle{Proper change of basis}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{red_line} \hlkwb{=} \hlkwd{c}\hldef{(}\hlnum{1}\hldef{, ev}\hlopt{$}\hldef{vectors[}\hlnum{2}\hldef{,}\hlnum{1}\hldef{]}\hlopt{/}\hldef{ev}\hlopt{$}\hldef{vectors[}\hlnum{1}\hldef{,}\hlnum{1}\hldef{])}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'ev' not found}}\begin{alltt}
\hldef{red_line} \hlkwb{=} \hldef{red_line}\hlopt{/}\hlkwd{sqrt}\hldef{(}\hlkwd{sum}\hldef{(red_line}\hlopt{^}\hlnum{2}\hldef{))}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'red\_line' not found}}\begin{alltt}
\hldef{green_line} \hlkwb{=} \hlkwd{c}\hldef{(}\hlnum{1}\hldef{, ev}\hlopt{$}\hldef{vectors[}\hlnum{2}\hldef{,}\hlnum{2}\hldef{]}\hlopt{/}\hldef{ev}\hlopt{$}\hldef{vectors[}\hlnum{1}\hldef{,}\hlnum{2}\hldef{])}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'ev' not found}}\begin{alltt}
\hldef{green_line} \hlkwb{=} \hldef{green_line}\hlopt{/}\hlkwd{sqrt}\hldef{(}\hlkwd{sum}\hldef{(green_line}\hlopt{^}\hlnum{2}\hldef{))}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'green\_line' not found}}\begin{alltt}
\hldef{augmented_M} \hlkwb{=} \hlkwd{cbind}\hldef{(red_line,green_line,} \hlkwd{diag}\hldef{(}\hlnum{2}\hldef{))}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'red\_line' not found}}\begin{alltt}
\hldef{P} \hlkwb{=} \hlkwd{rref}\hldef{(augmented_M)[,}\hlnum{3}\hlopt{:}\hlnum{4}\hldef{]}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'augmented\_M' not found}}\begin{alltt}
\hldef{tmp_in} \hlkwb{=} \hlkwd{matrix}\hldef{(}\hlkwd{c}\hldef{(data}\hlopt{$}\hldef{weight.c, data}\hlopt{$}\hldef{height.c),} \hlkwc{nc} \hldef{=} \hlnum{2}\hldef{)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in data\$weight.c: object of type 'closure' is not subsettable}}\begin{alltt}
\hldef{tmp_out} \hlkwb{=} \hlkwd{c}\hldef{()}
\hlkwa{for} \hldef{(i} \hlkwa{in} \hlnum{1}\hlopt{:}\hlkwd{dim}\hldef{(tmp_in)[}\hlnum{1}\hldef{]) \{}
    \hldef{tmp_out} \hlkwb{=} \hlkwd{rbind}\hldef{(tmp_out,} \hlkwd{t}\hldef{(P} \hlopt{%*%} \hldef{tmp_in[i,]))}
\hldef{\}}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'tmp\_in' not found}}\begin{alltt}
\hldef{data}\hlopt{$}\hldef{weight.c_r2} \hlkwb{=} \hldef{tmp_out[,}\hlnum{1}\hldef{]}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in data\$weight.c\_r2 = tmp\_out[, 1]: object of type 'closure' is not subsettable}}\begin{alltt}
\hldef{data}\hlopt{$}\hldef{height.c_r2} \hlkwb{=} \hldef{tmp_out[,}\hlnum{2}\hldef{]}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in data\$height.c\_r2 = tmp\_out[, 2]: object of type 'closure' is not subsettable}}

{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in (function (cond) : error in evaluating the argument 'x' in selecting a method for function 'plot': object of type 'closure' is not subsettable}}

{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in int\_abline(a = a, b = b, h = h, v = v, untf = untf, ...): plot.new has not been called yet}}

{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in int\_abline(a = a, b = b, h = h, v = v, untf = untf, ...): plot.new has not been called yet}}\end{kframe}
\end{knitrout}
\end{frame}

\maxFrameImage{FIGS/L12-plot-hockey-proper-changed-basis-1.pdf}


\begin{frame}[fragile]\frametitle{PCA using built-in functions}
Now do things ``properly''
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{GS} \hlkwb{=} \hldef{pracma}\hlopt{::}\hlkwd{gramSchmidt}\hldef{(}\hlkwc{A} \hldef{= ev}\hlopt{$}\hldef{vectors,} \hlkwc{tol} \hldef{=} \hlnum{1e-10}\hldef{)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'ev' not found}}\begin{alltt}
\hldef{GS}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'GS' not found}}\end{kframe}
\end{knitrout}
\end{frame}


\begin{frame}[fragile]\frametitle{PCA using built-in functions}
Now recall we saw a theorem that told us how to construct a new basis..
\vfill
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{A}\hlkwb{=}\hlkwd{matrix}\hldef{(}\hlkwd{c}\hldef{(GS}\hlopt{$}\hldef{Q,}\hlnum{1}\hldef{,}\hlnum{0}\hldef{,}\hlnum{0}\hldef{,}\hlnum{1}\hldef{),} \hlkwc{nr} \hldef{=} \hlnum{2}\hldef{)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'GS' not found}}\begin{alltt}
\hldef{A}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'A' not found}}\begin{alltt}
\hldef{pracma}\hlopt{::}\hlkwd{rref}\hldef{(A)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'A' not found}}\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile]\frametitle{PCA using built-in functions}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{P} \hlkwb{=} \hldef{pracma}\hlopt{::}\hlkwd{rref}\hldef{(A)[,}\hlkwd{c}\hldef{(}\hlnum{3}\hldef{,}\hlnum{4}\hldef{)]}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'A' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'P' not found}}\begin{alltt}
\hldef{X.new} \hlkwb{=} \hldef{X} \hlopt{%*%} \hlkwd{t}\hldef{(P)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'X' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'plot': object 'X.new' not found}}\end{kframe}
\end{knitrout}
\end{frame}

\maxFrameImage{FIGS/L12-plot-hockey-centred-evector-3-1.pdf}



%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%
\subsection{Back to fingerprints}
\newSubSectionSlide{FIGS-slides-admin/Gemini_Generated_Image_ut188hut188hut18.jpeg}


\begin{frame}
We get the data from \href{https://repository.lboro.ac.uk/articles/dataset/Height_weight_and_fingerprint_measurements_collected_from_200_participants/7539206}{here}
\vfill
This time, we first download the data, then open the file
\vfill
The file is an excel table, so we need to use a library for doing that
\end{frame}


\begin{frame}[fragile]\frametitle{Loading the excel fingerprint data}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{download.file}\hldef{(}\hlkwc{url} \hldef{=} \hlsng{"https://repository.lboro.ac.uk/ndownloader/files/14015774"}\hldef{,}
             \hlkwc{destfile} \hldef{=} \hlsng{"../CODE/fingerprint_data.xlsx"}\hldef{)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in download.file(url = "{}https://repository.lboro.ac.uk/ndownloader/files/14015774"{}, : cannot open URL 'https://repository.lboro.ac.uk/ndownloader/files/14015774'}}\begin{alltt}
\hldef{data} \hlkwb{=} \hldef{openxlsx}\hlopt{::}\hlkwd{read.xlsx}\hldef{(}\hlsng{"../CODE/fingerprint_data.xlsx"}\hldef{)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in read.xlsx.default("{}../CODE/fingerprint\_data.xlsx"{}): File does not exist.}}\begin{alltt}
\hlkwd{head}\hldef{(data,} \hlkwc{n}\hldef{=}\hlnum{3}\hldef{)}
\end{alltt}
\begin{verbatim}
##                                                                             
## 1 function (..., list = character(), package = NULL, lib.loc = NULL,        
## 2     verbose = getOption("verbose"), envir = .GlobalEnv, overwrite = TRUE) 
## 3 {
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}


\begin{frame}[fragile]\frametitle{Some wrangling}
Let us rework the names of columns a bit, for convenience. Let us also get rid of a few columns we are not using
\vfill
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{data} \hlkwb{=} \hldef{data[,}\hlnum{2}\hlopt{:}\hlkwd{dim}\hldef{(data)[}\hlnum{2}\hldef{]]}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in 2:dim(data)[2]: argument of length 0}}\begin{alltt}
\hlkwd{colnames}\hldef{(data)} \hlkwb{=} \hlkwd{c}\hldef{(}\hlsng{"gender"}\hldef{,} \hlsng{"age"}\hldef{,} \hlsng{"handedness"}\hldef{,} \hlsng{"height"}\hldef{,} \hlsng{"weight"}\hldef{,}
                  \hlsng{"fing_temp"}\hldef{,} \hlsng{"fing_height"}\hldef{,} \hlsng{"fing_width"}\hldef{,}
                  \hlsng{"fing_area"}\hldef{,} \hlsng{"fing_circ"}\hldef{)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in `colnames<-`(`*tmp*`, value = c("{}gender"{}, "{}age"{}, "{}handedness"{}, : attempt to set 'colnames' on an object with less than two dimensions}}\begin{alltt}
\hlkwd{head}\hldef{(data,} \hlkwc{n}\hldef{=}\hlnum{3}\hldef{)}
\end{alltt}
\begin{verbatim}
##                                                                             
## 1 function (..., list = character(), package = NULL, lib.loc = NULL,        
## 2     verbose = getOption("verbose"), envir = .GlobalEnv, overwrite = TRUE) 
## 3 {
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}



\begin{frame}\frametitle{Some wrangling -- Centering}
Plotting all these variables is complicated, so we forgo this for the time being
\vfill
Let us centre the data. That there are some \code{NA} values, so we remove them using the function \code{complete.cases}, which identifies rows where at least one of the variables is \code{NA}
\vfill
(We could also use \code{na.rm = TRUE} when taking the average to remove these values.) 
\vfill
We make new columns with the prefix \code{.c}, just to still have the initial data handy if need be.
\end{frame}

\begin{frame}[fragile]\frametitle{Some wrangling -- Centering}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{data} \hlkwb{=} \hldef{data[}\hlkwd{complete.cases}\hldef{(data),]}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in complete.cases(data): invalid 'type' (closure) of argument}}\begin{alltt}
\hldef{to_centre} \hlkwb{=} \hlkwd{c}\hldef{(}\hlsng{"age"}\hldef{,} \hlsng{"height"}\hldef{,}
              \hlsng{"weight"}\hldef{,} \hlsng{"fing_temp"}\hldef{,}
              \hlsng{"fing_height"}\hldef{,} \hlsng{"fing_width"}\hldef{,}
              \hlsng{"fing_area"}\hldef{,} \hlsng{"fing_circ"}\hldef{)}
\hlkwa{for} \hldef{(c} \hlkwa{in} \hldef{to_centre) \{}
    \hldef{new_c} \hlkwb{=} \hlkwd{sprintf}\hldef{(}\hlsng{"%s.c"}\hldef{, c)}
    \hldef{data[[new_c]]} \hlkwb{=} \hldef{data[[c]]} \hlopt{-} \hlkwd{mean}\hldef{(data[[c]],} \hlkwc{na.rm} \hldef{=} \hlnum{TRUE}\hldef{)}
\hldef{\}}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in data[[c]]: object of type 'closure' is not subsettable}}\begin{alltt}
\hlkwd{head}\hldef{(data)}
\end{alltt}
\begin{verbatim}
##                                                                             
## 1 function (..., list = character(), package = NULL, lib.loc = NULL,        
## 2     verbose = getOption("verbose"), envir = .GlobalEnv, overwrite = TRUE) 
## 3 {                                                                         
## 4     fileExt <- function(x) {                                              
## 5         db <- grepl("\\\\.[^.]+\\\\.(gz|bz2|xz)$", x)                     
## 6         ans <- sub(".*\\\\.", "", x)
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}



\begin{frame}[fragile]\frametitle{Covariance matrix}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{X} \hlkwb{=} \hlkwd{as.matrix}\hldef{(data[, to_centre])}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in (function (cond) : error in evaluating the argument 'x' in selecting a method for function 'as.matrix': object of type 'closure' is not subsettable}}\begin{alltt}
\hldef{S} \hlkwb{=} \hlnum{1}\hlopt{/}\hldef{(}\hlkwd{dim}\hldef{(X)[}\hlnum{1}\hldef{]}\hlopt{-}\hlnum{1}\hldef{)}\hlopt{*}\hlkwd{t}\hldef{(X)} \hlopt{%*%} \hldef{X}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'X' not found}}\begin{alltt}
\hldef{S}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'S' not found}}\end{kframe}
\end{knitrout}
\end{frame}




\begin{frame}[fragile]\frametitle{Eigenvalues}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{ev} \hlkwb{=} \hlkwd{eigen}\hldef{(S)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'S' not found}}\begin{alltt}
\hldef{ev}\hlopt{$}\hldef{values}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'ev' not found}}\end{kframe}
\end{knitrout}
\vfill
Let us add the singular values to \code{ev}
\vfill
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{ev}\hlopt{$}\hldef{sing_values} \hlkwb{=} \hlkwd{sqrt}\hldef{(ev}\hlopt{$}\hldef{values)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'ev' not found}}\end{kframe}
\end{knitrout}
\end{frame}



\begin{frame}[fragile]\frametitle{Use built-in functions}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{GS} \hlkwb{=} \hldef{pracma}\hlopt{::}\hlkwd{gramSchmidt}\hldef{(}\hlkwc{A} \hldef{= ev}\hlopt{$}\hldef{vectors)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'ev' not found}}\begin{alltt}
\hldef{GS}\hlopt{$}\hldef{Q}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'GS' not found}}\begin{alltt}
\hlcom{# Just to check that Q is indeed with normalised columns}
\hlkwd{colSums}\hldef{(GS}\hlopt{$}\hldef{Q[,}\hlnum{1}\hlopt{:}\hlkwd{dim}\hldef{(GS}\hlopt{$}\hldef{Q)[}\hlnum{2}\hldef{]]}\hlopt{^}\hlnum{2}\hldef{)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'colSums': object 'GS' not found}}\begin{alltt}
\hldef{GS}\hlopt{$}\hldef{Q[,}\hlnum{1}\hldef{]} \hlopt{%*%} \hldef{GS}\hlopt{$}\hldef{Q[,}\hlnum{2}\hldef{]}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'GS' not found}}\end{kframe}
\end{knitrout}
So \code{Q} is indeed an orthogonal matrix
\end{frame}



\begin{frame}[fragile]\frametitle{Some wrangling}
Now recall we saw a theorem that told us how to construct a new basis..


\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# Make an identity matrix}
\hldef{Id} \hlkwb{=} \hlkwd{diag}\hldef{(}\hlkwd{dim}\hldef{(GS}\hlopt{$}\hldef{Q)[}\hlnum{1}\hldef{])}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'diag': object 'GS' not found}}\begin{alltt}
\hlcom{# Make the augmented matrix}
\hldef{A} \hlkwb{=} \hlkwd{cbind}\hldef{(GS}\hlopt{$}\hldef{Q, Id)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'GS' not found}}\begin{alltt}
\hlcom{# Compute the RREF and extract the relevant matrix}
\hldef{P} \hlkwb{=} \hldef{pracma}\hlopt{::}\hlkwd{rref}\hldef{(A)[,(}\hlkwd{dim}\hldef{(GS}\hlopt{$}\hldef{Q)[}\hlnum{2}\hldef{]}\hlopt{+}\hlnum{1}\hldef{)}\hlopt{:}\hlkwd{dim}\hldef{(A)[}\hlnum{2}\hldef{]]}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'A' not found}}\begin{alltt}
\hldef{X.new} \hlkwb{=} \hldef{X} \hlopt{%*%} \hlkwd{t}\hldef{(P)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'X' not found}}\end{kframe}
\end{knitrout}
\end{frame}


\begin{frame}[fragile]\frametitle{Use built-in functions}
Use the built in function \code{prcomp} or \code{PCA} from the \code{FactoMineR} package
\vfill
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# data.pca = prcomp(X, center = TRUE, scale = TRUE)}
\hldef{data.pca} \hlkwb{=} \hlkwd{PCA}\hldef{(X,} \hlkwc{scale.unit} \hldef{=} \hlnum{TRUE}\hldef{,} \hlkwc{graph} \hldef{=} \hlnum{FALSE}\hldef{)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'X' not found}}\begin{alltt}
\hlkwd{summary}\hldef{(data.pca)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': object 'data.pca' not found}}\end{kframe}
\end{knitrout}
\end{frame}


\begin{frame}[fragile]\frametitle{Percentage of variance}
The ``proportion of variance'' (or ``percentage of variance'') information is actually the proportion (and then cumulative proportion) represented by the singular value associated to each principal component
\vfill
We check this (approximately) by comparing with the singular values we computed
\vfill
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{ev}\hlopt{$}\hldef{sing_values}\hlopt{/}\hldef{(}\hlkwd{sum}\hldef{(ev}\hlopt{$}\hldef{sing_values))}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'ev' not found}}\begin{alltt}
\hlkwd{cumsum}\hldef{(ev}\hlopt{$}\hldef{sing_values)}\hlopt{/}\hldef{(}\hlkwd{sum}\hldef{(ev}\hlopt{$}\hldef{sing_values))}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'ev' not found}}\end{kframe}
\end{knitrout}
\end{frame}



% \begin{frame}[fragile]\frametitle{Some wrangling}
% <<>>=
% str(data.pca)
% @
% 
% 
% <<>>=
% #library(devtools)
% #install_github("vqv/ggbiplot")
% library(ggbiplot)
% @
% 
% \end{frame}
% 
% 
% \begin{frame}[fragile]\frametitle{Some wrangling}
% <<>>=
% ggbiplot(data.pca, groups = data$handedness)
% @
% \end{frame}

\begin{frame}[fragile]\frametitle{Plot results}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{plot.PCA}\hldef{(data.pca,} \hlkwc{axes} \hldef{=} \hlkwd{c}\hldef{(}\hlnum{1}\hldef{,}\hlnum{2}\hldef{),} \hlkwc{choix} \hldef{=} \hlsng{"ind"}\hldef{,} \hlkwc{habillage} \hldef{=} \hlnum{4}\hldef{)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: object 'data.pca' not found}}\end{kframe}
\end{knitrout}
\end{frame}

\maxFrameImage{FIGS/L12-plot-PCA-1-1.pdf}

% \begin{frame}[fragile]\frametitle{Plot results with ellipses}
% <<plot-PCA-2>>=
% plotellipses(data.pca)
% @
% \end{frame}
% 
% \maxFrameImage{knitr::fig_chunk("plot-PCA-2", "pdf")}


% \begin{frame}[fragile]\frametitle{Some wrangling}
% Not that it makes much difference, but here we realise that handedness is badly encoded, in the sense that there are some individuals with lowercase handedness and others where the word starts with a capital letter. Let us fix this and plot again
% 
% <<>>=
% data$handedness = tolower(data$handedness)
% ggbiplot(data.pca, groups = data$handedness)
% @
% \end{frame}
% 
% 
% \begin{frame}[fragile]\frametitle{Some wrangling}
% Something else you can plot: ellipses containing most elements in a group, for the groups we have selected (here, handedness).
% 
% 
% <<>>=
% ggbiplot(data.pca, groups = data$handedness, ellipse = TRUE)
% @
% \end{frame}





%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%
\section{Support vector machines}
\newSectionSlide{FIGS-slides-admin/Gemini_Generated_Image_c06eixc06eixc06e.jpeg}

%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%
\subsection{Clustering and classification}
\newSubSectionSlide{FIGS-slides-admin/Gemini_Generated_Image_c06eixc06eixc06e.jpeg}

\begin{frame}{Clustering vs classification}
    Clustering is partitioning an unlabelled dataset into groups of similar objects
    \vfill
    Classification sorts data into specific categories using a labelled dataset
\end{frame}

\begin{frame}{Clustering}
    From \href{https://en.wikipedia.org/wiki/Cluster_analysis}{Wikipedia}
    \begin{quote}
        \textbf{Cluster analysis} or \textbf{clustering} is the task of grouping a set of objects in such a way that objects in the same group (called a \textbf{cluster}) are more similar (in some sense) to each other than to those in other groups (clusters).
    \end{quote}
    \vfill
    There are a myriad of ways to do clustering, this is an extremely active field of research and application. See the Wikipedia page for leads
\end{frame}


\begin{frame}{Classification}
    From \href{https://en.wikipedia.org/wiki/Statistical_classification}{Wikipedia}
    \begin{quote}
        In statistics, \textbf{classification} is the problem of identifying which of a set of categories (sub-populations) an observation (or observations) belongs to. Examples are assigning a given email to the "spam" or "non-spam" class, and assigning a diagnosis to a given patient based on observed characteristics of the patient (sex, blood pressure, presence or absence of certain symptoms, etc.).
    \end{quote}
\end{frame}




% Save counters for next file

% Save theorem count for next file
\end{document}
